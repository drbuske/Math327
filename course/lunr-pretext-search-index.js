var ptx_lunr_search_style = "textbook";
var ptx_lunr_docs = [
{
  "id": "ch-Textbook-2",
  "level": "1",
  "url": "ch-Textbook-2.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 0.2 - What are Differential Equations?",
  "body": " Daily Prep 0.2 - What are Differential Equations?   Overview  Differential equations are central to science and engineering because the laws of physics are written in this form and they describe how quantities change over time. You have already encountered and even solved simple differential equations in calculus, even if you did not recognize them. This section illustrates what a differential equation looks like and clarifies key ideas like dependent and independent variables. It also demonstrates that many differential equations can have multiple valid solutions, showing how to check a proposed solution by substitution.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Recognize what a differential equation is and identify the dependent and independent variables in an example.    Understand that differential equations arise naturally from physical laws such as Newton’s law of cooling.    Verify whether a proposed function is a solution by computing its derivative and substituting into the equation.      Learn!  Complete the actions listed below.     Watch video Intro to Differential Equations .     Read  Subsection 0.2.1: Differential equations .     Watch video The Key Definitions of Differential Equations .     Read  Subsection 0.2.2: Solutions of differential equations .     Read  Subsection 0.2.3: Differential equations in practice and Subsection 0.2.4: Four fundamental equations .     Watch  Introduction to differential equations (34:13) for a lecture on section 0.2.     Do  Exercise 0.2.1 , Exercise 0.2.2 .     Do  Subsection 0.2.5: Exercises 0.2.5, 0.2.6, 0.2.7, 0.2.8, 0.2.19 .     Read  Section 0.3: Classification of differential equations .     Watch  Classification of differential equations (31:23) for a lecture on section 0.3.     Do  Subsection 0.3.1: Exercises 0.3.1, 0.3.5 .    Try these additional questions. If necessary, use AI to guide your thinking.   What does the order of a differential equation refer to?    Values are typical solutions to algebraic equations (e.g. solves ). What objects are typical solutions to differential equations?    Give a specific example of a differential equation that is autonomous and one that is not.    (Newton’s Law of Cooling)  The time rate of change of the temperature of a body is proportional to the difference between and the temperature of the surrounding medium. That is, where is a positive constant.    If , is positive, negative, or zero? Is the body warming or cooling?    What can be said if ?      State the order of each differential equation and determine whether it is linear or nonlinear.                              Do MyOpenMath questions from these sections.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Explain why differential equations can have infinitely many solutions and interpret how solution families arise (e.g., from arbitrary constants).    Analyze an integral function using the usual techniques from differential calculus.    Analyze how different solutions correspond to different physical scenarios or initial conditions.    Interpret the structure of a first‑order linear differential equation and understand how it models time‑varying physical processes (such as oscillating ambient temperature).     "
},
{
  "id": "ch-Textbook-3",
  "level": "1",
  "url": "ch-Textbook-3.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 1.1 - Integrals as Solutions",
  "body": " Daily Prep 1.1 - Integrals as Solutions   Overview  This section shows how certain first-order differential equations can be solved simply by antidifferentiating. When the equation has the form , its general solution is just an antiderivative of plus a constant. The text also clarifies the difference between definite and indefinite integrals and explains how initial conditions lead to a definite‑integral formula for the solution.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Understand that a first-order ODE of the form is solved by finding an antiderivative of .    Recognize the role of initial conditions in determining the specific constant .    Distinguish between definite and indefinite integrals and know that the definite integral gives a computable expression for solutions.      Learn!  Complete the actions listed below.     Watch video Integrals as Solutions (6:23) by Mathispower4u.     Read  Section 1.1: Integrals as solutions up to Example 1.1.4.     Read  Example 1.1.4 and then think about the following question. In this example, is treated as a solution separately. Why? Plot this solution. Then, verify that is indeed a solution.     Read  Example 1.1.5 .     Do the following for Example 1.1.5. Plot the speed against time of the car (labeling your axes with appropriate units). Then, plot the distance traveled against time . Label your axes.     Read  Example 1.1.6 .     Do the exercise mentioned at the end of Example 1.1.6.     Watch  Integrals as Solutions (34:22) for a lecture on section 1.1.     Do  Subsection 1.1.1: Exercises 1.1.2, 1.1.4, 1.1.15, 1.1.18 .    Try these additional questions. If necessary, use AI to guide your thinking.   Write a differential equation that is a model for the following: In a city with a fixed population of persons, the time rate of change of the number of those persons infected with a certain contagious disease is proportional to the product of the number who have the disease and the number who do not.    Substitute into the differential equation to determine all values of the constant for which is a solution.    Write a differential equation that is a mathematical model for each situation.   The acceleration of a Lamborghini is proportional to the difference between 250 km\/h and the velocity of the car.  In a city having a fixed of population persons, the time rate of change of the number of those persons who have heard a certain rumor is proportional to the number of those who have not yet heard the rumor.     Suppose that a football coach gets a salary of one million dollars now, and a raise of every year (so exponential model, like population of bacteria). Let be the salary in millions of dollars, and is time in years.    What is and .    Approximately how many years will it take for the salary to be 10 million?    Approximately how many years will it take for the salary to be 20 million?      Sid is in a car traveling at speed miles per hour away from Las Vegas, where is in hours. At , Sid is 10 miles away from Vegas. How far from Vegas is Sid 2 hours later?       (Optional) Watch  a video on chapter 0 and section 1.1 by Mark Sullivan (43:05) .     Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Explain why antidifferentiation works as a universal method when depends only on , using the Fundamental Theorem of Calculus.    Express solutions with initial conditions using definite-integral form .    Articulate the conceptual difference between the definite integral (a number) and the indefinite integral (a family of antiderivatives).     "
},
{
  "id": "ch-Textbook-4",
  "level": "1",
  "url": "ch-Textbook-4.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 1.2 - Slope Fields",
  "body": " Daily Prep 1.2 - Slope Fields   Overview  In this section, we are introduced to slope fields as a geometric way to visualize first‑order differential equations of the form . A slope field assigns a small line segment with slope at each point of the plane, allowing us to see how solution curves must behave without solving the equation analytically. By following these slopes, we can sketch approximate solutions that satisfy various initial conditions and observe how small changes in starting points can lead to noticeably different solution behaviors.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Understand that a slope field represents the slope at each point for an ODE .    Be able to interpret slope fields to sketch approximate solution curves passing through given initial conditions.    Recognize that slope fields allow qualitative predictions when explicit solutions are difficult or impossible to obtain.      Learn!  Complete the actions listed below.     Watch video Introduction to Slope Fields (7:11) by Mathispower4u.     Watch video Video 1.2.1: Slope Fields by Trevor Bazett.     Read  Subsection 1.2.1: Slope fields . Be sure to experiment with the GeoGebra activity found in Example 1.2.1 .     Watch  Video 1.2.2: Existence and Uniqueness by Trevor Bazett.     Read  Subsection 1.2.2: Existence and uniqueness .    Try these additional questions. If necessary, use AI to guide your thinking.   What do you see as the value in slope fields? What role does technology play in this concept?    In your own words, what does Picard's theorem say?        Watch  Slope Field (30:34) for a lecture on section 1.2.     Watch  Create Slope Fields Using GeoGebra (2:49) .     Do  Subsection 1.2.3: Exercises 1.2.2, 1.2.3, 1.2.4, 1.2.5, 1.2.6, 1.2.10, 1.2.11, 1.2.14, 1.2.16, 1.2.18. .    Try these additional questions. If necessary, use AI to guide your thinking.   Consider the differential equation    Fill in the table below with the slopes at various values of and .  Slopes at various values of and for .                                                                                                   Plot the slopes in the table above to form a slope field.    On the given slope field in , sketch a solution curve to the initial value problem    Slope field for .   A slope field for y' = x-2y.        In is a slope field for .    Sketch a solution to the initial value problem , .    Sketch a solution to the initial value problem , .    Sketch a solution to the initial value problem , .    Does the IVP , have a solution for every ? If so, is that solution unique?   Slope field for .   A slope field for y' = 1.5y.        The initial value problem has no solution. Explain why this is the case in words using the slope field shown in .   Slope field for .   A slope field for y' = 1 over x.      The initial value problem has two solutions: and . Verify, algebraically, that both of these are indeed solutions. Then, draw both of these solutions on the direction field shown in .   Slope field for .   A slope field for y' = 2 times the square root of y.      [Multiple-choice] The slope field in indicates the differential equation has which form?   A mystery slope field.   A mystery slope field.                 [Multiple-choice] The slope field in indicates the differential equation has which form?   Another mystery slope field.   Another mystery slope field.                 [Multiple-choice] The slope field in indicates the differential equation has which form?   And yet another mystery slope field.   And yet another mystery slope field.                 Solve the initial value problem Hint: 'Separate' the variables and by, informally, writing the equation as     Use technology to generate the slope field of . Then, sketch likely solution curves for each of the following initial-value problems.                     Repeat the above question for the differential equation and the initial-value problems below.                   (Optional) Watch  a video on section 1.2 by Math Matt (18:38) .     Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Analyze how small changes in initial conditions can yield significantly different solution behaviors by examining the slope field.    Compare slope fields for two different differential equations to deduce how the structure of influences long‑term solution behavior.    Use geometric reasoning from slope fields to anticipate qualitative features such as stability, divergence, and monotonicity of solutions.     "
},
{
  "id": "ch-Textbook-4-2-2",
  "level": "2",
  "url": "ch-Textbook-4.html#ch-Textbook-4-2-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "slope fields "
},
{
  "id": "SlopeFieldData",
  "level": "2",
  "url": "ch-Textbook-4.html#SlopeFieldData",
  "type": "Table",
  "number": "1",
  "title": "Slopes at various values of <span class=\"process-math\">\\(x\\)<\/span> and <span class=\"process-math\">\\(y\\)<\/span> for <span class=\"process-math\">\\(\\frac{dy}{dx} = x - 2y\\text{.}\\)<\/span>",
  "body": " Slopes at various values of and for .                                                                                                "
},
{
  "id": "SlopeField2026a",
  "level": "2",
  "url": "ch-Textbook-4.html#SlopeField2026a",
  "type": "Figure",
  "number": "2",
  "title": "",
  "body": " Slope field for .   A slope field for y' = x-2y.   "
},
{
  "id": "SlopeField2026b",
  "level": "2",
  "url": "ch-Textbook-4.html#SlopeField2026b",
  "type": "Figure",
  "number": "3",
  "title": "",
  "body": " Slope field for .   A slope field for y' = 1.5y.   "
},
{
  "id": "SlopeField2026c",
  "level": "2",
  "url": "ch-Textbook-4.html#SlopeField2026c",
  "type": "Figure",
  "number": "4",
  "title": "",
  "body": " Slope field for .   A slope field for y' = 1 over x.   "
},
{
  "id": "SlopeField2026d",
  "level": "2",
  "url": "ch-Textbook-4.html#SlopeField2026d",
  "type": "Figure",
  "number": "5",
  "title": "",
  "body": " Slope field for .   A slope field for y' = 2 times the square root of y.   "
},
{
  "id": "SlopeField2026e",
  "level": "2",
  "url": "ch-Textbook-4.html#SlopeField2026e",
  "type": "Figure",
  "number": "6",
  "title": "",
  "body": " A mystery slope field.   A mystery slope field.   "
},
{
  "id": "SlopeField2026f",
  "level": "2",
  "url": "ch-Textbook-4.html#SlopeField2026f",
  "type": "Figure",
  "number": "7",
  "title": "",
  "body": " Another mystery slope field.   Another mystery slope field.   "
},
{
  "id": "SlopeField2026g",
  "level": "2",
  "url": "ch-Textbook-4.html#SlopeField2026g",
  "type": "Figure",
  "number": "8",
  "title": "",
  "body": " And yet another mystery slope field.   And yet another mystery slope field.   "
},
{
  "id": "ch-Textbook-5",
  "level": "1",
  "url": "ch-Textbook-5.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 1.3 - Separable Equations",
  "body": " Daily Prep 1.3 - Separable Equations   Overview  This section introduces separable differential equations , a class of first‑order ODEs that can be rewritten so that all -terms appear on one side and all -terms on the other. Once written in the form , both sides can be integrated to obtain a general (often implicit) solution. The section demonstrates how separation works, why special solutions like must be considered, and how implicit solutions arise naturally when solving the resulting integrals. It also clarifies that separation is justified rigorously through substitution rather than by treating as an algebraic fraction.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Identify when a differential equation can be written in the separable form .    Correctly separate variables to obtain .    Integrate both sides to obtain the general (possibly implicit) solution.      Learn!  Complete the actions listed below.     Watch video Introduction to Separation of Variables to Solve (6:25) by Mathispower4u.     Watch  Video 1.3.1: Separation of Variables by Trevor Bazett.     Read  Subsection 1.3.1: Separable equations and Subsection 1.3.2: Implicit solutions .     Do the computation left to the reader at the beginning of Subsection 1.3.2: Implicit solutions .     Watch  Video 1.3.2: Newton’s Law of Cooling by Trevor Bazett.     Watch  Example 1.3.2 Solve a Separable Differentiable Equation Using Factor by Grouping by Mathispower4u.     Read  Subsection 1.3.3: Examples of separable equations . Refer to Example 1.3.5 . What is a singular solution?     Watch  Separable Equations (39:44) for a lecture on section 1.3.     Do  Subsection 1.3.4: Exercises 1.3.1, 1.3.4, 1.3.9, 1.3.11. .    Try these additional questions. If necessary, use AI to guide your thinking.    Solve the initial value problem Hint: 'Separate' the variables and by, informally, writing the equation as     Consider the ODE . Using separation of variables, we earlier found a general solution to be . Hence, the IVP has unique solution .   What is the unique solution to the following IVP?   Why does the method of separation of variables `lose' the solution found in (a)?       (Optional) Watch more videos on solving separable equations via a YouTube playlist of The Math Sorcerer.     Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Justify separation using the chain rule and substitution rather than informal manipulation of .    Identify and include singular or special solutions (such as ) that arise when dividing by .    Recognize when the resulting integrals lead to solutions that must remain in implicit form and verify such solutions by differentiation.     "
},
{
  "id": "ch-Textbook-5-2-2",
  "level": "2",
  "url": "ch-Textbook-5.html#ch-Textbook-5-2-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "separable differential equations "
},
{
  "id": "ch-Textbook-6",
  "level": "1",
  "url": "ch-Textbook-6.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 1.4 - Linear Equations and the Integrating Factor",
  "body": " Daily Prep 1.4 - Linear Equations and the Integrating Factor   Overview  This section introduces first-order linear differential equations of the form and develops the integrating factor method for solving them. By multiplying the equation by a specially chosen function , the left-hand side becomes the derivative of a product, allowing the equation to be integrated directly. The integrating factor turns out to be , and this method provides a systematic way to solve any linear first-order ODE, leading to an explicit formula for the solution when the required integrals can be computed.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Recognize when an equation is a first-order linear ODE of the form .    Understand the purpose of an integrating factor and how it is used to rewrite the equation as the derivative of a product.    Apply the integrating factor method to obtain a solvable integrated equation.      Learn!  Complete the actions listed below.     Watch video Introduction to Solving a First Order Linear Differential Equation Using an Integrating Factor (5:43) by Mathispower4u.     Watch  Video 1.4.1: Linear Equations and Integrating Factors by Trevor Bazett.     Read  Section 1.4: Linear equations and the integrating factor .     Watch  Video 1.4.2: Integrating Factor Examples by Trevor Bazett.    Try these additional questions. If necessary, use AI to guide your thinking.   There is a `trick' to solving linear first order differential equations described in this section that involves multiplying by a function . What differentiation rule lies at the heart of this trick? [Hint: It is not the power rule.]    In Example 1.4.1 , . Note that . However, the text simply writes and does not write the arbitrary constant of integration ? Why is this not necessary?    Multiply on both sides by by .   What is the left-hand side?  Compute .  How should $I(x)$ be chosen so that (a) and (b) are always equal? That is, what (differential) equation must it solve?  Solve for in terms of using separation of variables.     Here, we solve the initial value problem    Identify the integrating factor .  Upon multiplying both sides of the differential equation by , the left-hand side can be written as .  What is the general solution to the differential equation?         Watch  Integrating Factor to Solve a Differential Equation (3:29) by Patrick JMT.     Watch  Linear equations and the integrating factor (28:49) for a lecture on section 1.4.     Do  Subsection 1.4.1: Exercises 1.4.1, 1.4.2, 1.4.12, 1.4.13. .    Try these additional questions. If necessary, use AI to guide your thinking.   A nitric acid solution flows at a constant rate of 6 L\/min into a large tank that initially held 200 L of a 0.5% nitric acid solution. The solution inside the tank remains stirred and flows out at a rate of 8 L\/min. If the solution entering the tank is 20% nitric acid, determine the volume of nitric acid in the tank after minutes.   Nitric acid in a tank.   Diagram of a mixing tank showing a 20% acid solution flowing in at 6 liters per minute on the left, and a mixture flowing out at 8 liters per minute on the right. Inside the tank, the variable V(t) represents the volume of nitric acid after t minutes, with the initial condition V(0) = 1 liter.    Here, . Also,    Show that the solution to the initial value problem using an integrating factor is   After how many minutes is the tank empty?  It stands to reason that should hold and our model should be valid for . Does the graph of suggest this to be true?     At noon, a tank contains 100 L of solution in which 10 kg of chemical is dissolved. Solution containing 2 kg of the chemical per liter flows into the tank at 5 L\/min. The mixture is well-stirred and drawn off at a rate of 4 L\/min. If the tank holds 500 L, when does it overflow? If measures the number of minutes after noon, what is the mass of chemical, , in the tank (in kg) at any time ? [Set up an linear initial-value problem and solve.]    Consider a tank initially containing 200 gallons of pure water, and start adding saltwater (containing 3 ounces of salt per gallon of water) at a rate of 1\/2 gallon per minute. At the same time, the resulting mixture in the tank is drained at the rate of 1\/2 gallon per minute. As usual, the mixture in the tank is thoroughly and uniformly mixed at all times. Assume also that a device (similar to a human liver) is attached to the tank that each minute filters out half the salt in a single gallon from the mixture in the tank.  Let denote the number of ounces of salt in the tank at minutes after we start adding saltwater.   Find an initial-value problem that models this situation.  Use technology to sketch a slope field ( ) for this differential equation. Do any equilibrium solutions appear to exist? If so, where?  Solve the IVP to determine . Plot for the first 24 hours using the technology.  Compute .        (Optional) Watch video The Integrating Factor Method (9:55) from a friend of mine, Matthew Wright, at St. Olaf College.     Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Derive the integrating factor by requiring that the left-hand side become a product derivative.    Solve linear ODEs explicitly and check solutions using differentiation, including solutions involving initial conditions.    Explain why the constant of integration inside the integrating factor does not affect the final solution.     "
},
{
  "id": "ch-Textbook-6-2-2",
  "level": "2",
  "url": "ch-Textbook-6.html#ch-Textbook-6-2-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "linear differential equations integrating factor method "
},
{
  "id": "BrineTank1",
  "level": "2",
  "url": "ch-Textbook-6.html#BrineTank1",
  "type": "Figure",
  "number": "9",
  "title": "",
  "body": " Nitric acid in a tank.   Diagram of a mixing tank showing a 20% acid solution flowing in at 6 liters per minute on the left, and a mixture flowing out at 8 liters per minute on the right. Inside the tank, the variable V(t) represents the volume of nitric acid after t minutes, with the initial condition V(0) = 1 liter.   "
},
{
  "id": "ch-Textbook-7",
  "level": "1",
  "url": "ch-Textbook-7.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 1.6 - Autonomous Equations",
  "body": " Daily Prep 1.6 - Autonomous Equations   Overview  This section introduces autonomous differential equations , equations of the form whose rate of change depends only on the dependent variable and not on the indpendent variable (which is often time ). Because of this simplification, autonomous equations allow powerful qualitative analysis: identifying equilibrium (constant) solutions, determining critical points where , and analyzing the stability of these equilibria by observing how nearby solutions behave. Using examples such as Newton’s law of cooling and the logistic population model, the section shows how slope fields reveal long‑term behavior—such as convergence to a stable equilibrium or divergence from an unstable one—even without solving the ODE explicitly.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Recognize an autonomous equation as one of the form where the derivative depends only on the dependent variable.    Identify equilibrium (constant) solutions by finding critical points where .    Use slope fields to sketch and interpret basic qualitative behaviors of solutions over time.      Learn!  Complete the actions listed below.     Watch video Introduction to Autonomous Differential Equations (8:14) by Mathispower4u.     Watch  Video 1.6.1: Autonomous Equations by Trevor Bazett.     Read  Section 1.6: Autonomous equations .     Watch  Video 1.6.2: Logistic Equation by Trevor Bazett.    Try these additional questions. If necessary, use AI to guide your thinking.    In section 1.6 , you read the following sentence: Note also, by looking at the graph, that the solution is ``stable” in that small perturbations in do not lead to substantially different solutions as grows. What is meant by the word `perturbation' in this context?       Watch  Autonomous equations (39:07) for a lecture on section 1.6.     Do  Subsection 1.6.1: Exercises 1.6.1, 1.6.6, 1.6.9. .    Try these additional questions. If necessary, use AI to guide your thinking.   How does the solution to the autonomous IVP compare to the solution of the IVP ? Can you generalize this idea for any autonomous equation? A slope field for is given in .   A slope field for .   A slope field on a square coordinate grid, with short line segments slanting downward to the right above the x‑axis and slanting upward to the right below the x‑axis. Along the horizontal line y = 3 the segments are nearly horizontal. Slopes become steeper as y moves farther away from 3.      Values of for which are called critical points . They provide equilibrium solutions of the autonomous equation . That is, are constant solutions.  Why are equilibrium solutions constant solutions? Hint: Remember the result of the previous problem.      Determine the equilibrium solutions to Use the slope field shown in to confirm your finding.   A slope field for .   A slope field on a square grid showing short line segments that tilt downward to the right above the x‑axis and tilt upward to the right below the x‑axis. Near the horizontal line y = 2, the segments are nearly horizontal. The slopes become steeper as y moves away from 2 in either direction.     Solution curves often approach equilibrium solutions as increases, or move away as increases. This is called stability .   If all nearby solution curves approach , then the equilibrium is called a sink ( stable ).  If at least some nearby solution curves do not approach , then the equilibrium is called unstable .  If all nearby solution curves move away from , then the equilibrium is called a source (unstable).   Determine the stability of the two equilibrium solutions and to the equation       A disease is spreading through the country. Let be the number of people infected. Let the constant be the number of people susceptible to infection. The infection rate is proportional to the product of already infected people, , and the number of susceptible but uninfected people, .   Write down the differential equation.  Supposing , that is, some people are infected at time , what is .  Does the solution to part (b) agree with your intuition? Why or why not?        (Optional) Watch video Autonomous First-Order ODEs (32:30) from Understand to Learn.     Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Analyze stability of equilibrium points by determining whether nearby solutions move toward or away from them.    Describe long‑term behavior of solutions (e.g., convergence to stable equilibria, divergence from unstable ones) using graphical evidence alone.    Interpret models such as Newton’s cooling law and the logistic equation to understand how nonlinear autonomous equations can produce qualitatively different dynamics.     "
},
{
  "id": "ch-Textbook-7-2-2",
  "level": "2",
  "url": "ch-Textbook-7.html#ch-Textbook-7-2-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "autonomous differential equations "
},
{
  "id": "sec-Toprepareforclass16-3-8-1",
  "level": "2",
  "url": "ch-Textbook-7.html#sec-Toprepareforclass16-3-8-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "critical points equilibrium stability sink stable unstable source "
},
{
  "id": "ch-Textbook-8",
  "level": "1",
  "url": "ch-Textbook-8.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 1.7 - Numerical Methods: Euler’s Method",
  "body": " Daily Prep 1.7 - Numerical Methods: Euler's Method   Overview  Many differential equations cannot be solved exactly, yet we still need to understand how their solutions behave. Numerical methods provide a way to approximate solutions by replacing the continuous differential equation with a sequence of discrete steps that can be carried out by hand, by calculator, or by computer. In earlier chapters, slope fields offered a qualitative sense of how solutions evolve. Numerical methods build on this idea by giving a systematic procedure for constructing approximate solution curves.  The foundational idea is simple: if we know a point on a solution curve and its slope, then we can follow that slope a short distance to obtain an approximate value of the solution at a nearby point. Euler’s method, the first and simplest numerical technique introduced in this section, does exactly this. Although Euler’s method is only a rough approximation, it reveals the key principles that underlie more accurate methods and helps establish good computational habits.  This section emphasizes how to implement numerical procedures, how to interpret their results, and how to understand their limitations. Students learn how step size affects accuracy, how numerical instability can appear, and why different methods may behave differently even when applied to the same differential equation. By the end of the section, readers will have a practical toolkit for approximating solutions and for connecting analytic, graphical, and numerical viewpoints.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Understand the motivation for numerical methods when exact solutions to differential equations cannot be found easily or at all.    Explain the idea behind approximating a solution curve by following the slope given by a differential equation.    Use Euler’s method to generate approximate solution values for a first-order initial value problem with a given step size.   Interpret numerical approximations graphically and compare them with qualitative slope-field behavior.  Describe how step size affects the quality and accuracy of numerical approximations.     Learn!  Complete the actions listed below.     Watch video Introduction to Euler's Method to Approximate a Solution to an Initial Value Problem (6:40) by Mathispower4u.     Watch  Euler's Method (10:07) from Khan Academy.     Read  Section 1.7: Numerical methods: Euler’s method .     Watch  Euler's Method (Introduction and Example) (12:22) from blackpenredpen.     Experiment with an Euler's Method GeoGebra Applet from Juan Carlos Ponce Campuzano.    (Optional) Experiment with another Euler's Method Applet from MIT.     Watch  Numerical methods: Euler's method (50:33) for a lecture on section 1.7.     Watch  Euler's Method (20:49) by The Organic Chemistry Tutor.     Do  Subsection 1.7.1: Exercises 1.7.3, 1.7.4 .    (Optional) Watch video The Integrating Factor Method (9:55) from a friend of mine, Matthew Wright, at St. Olaf College.     Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Analyze sources of numerical error in Euler’s method, including local truncation error and the accumulation of global error.    Explain why some numerical methods may be unstable even when the analytic solution behaves well.    Compare Euler’s method with higher-order or improved methods in terms of accuracy and stability.   Evaluate how changing the step size influences numerical stability and identify when a numerical solution may no longer be reliable.    "
},
{
  "id": "ch-Textbook-9",
  "level": "1",
  "url": "ch-Textbook-9.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 2.1 - Second Order Linear ODEs",
  "body": " Daily Prep 2.1 - Second Order Linear ODEs   Overview  In this section, we will learn how to recognize, interpret, and solve second‑order linear ordinary differential equations, which take the general form . After rewriting such equations in the standardized form , we will explore the foundational structure of linear ODEs, including the distinction between homogeneous and nonhomogeneous equations and the crucial fact that no powers or nonlinear functions of , , or appear. A major focus is understanding the principle of superposition, which allows solutions of homogeneous equations to be combined into new solutions, and learning how this principle, along with existence and uniqueness results, gives linear ODEs a powerful and predictable solution theory. We will also be introduced to the operator viewpoint , which provides an elegant framework for understanding why linear equations behave so systematically.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Recognize the standard form of a second‑order linear ODE and identify its components.    Explain the difference between homogeneous and nonhomogeneous linear equations.    Describe the principle of superposition for solutions of linear homogeneous ODEs.      Learn!  Complete the actions listed below.     Watch video Video 2.1.1: 2nd Order Linear Equations by Trevor Bazett.     Read  Section 2.1: Second order linear ODEs .     Watch  Intro to Second Order Linear ODEs: Superposition, Existence\/Uniqueness\/Linear Independence (6:20) by Mathispower4u.     Watch  Determine if Two Functions are Linearly Dependent or Linearly Independent (5:05) by Mathispower4u.    (Optional) Watch  Ex 2.1B Find a General Solution to a 2nd Order Linear Homogeneous DE (Reduction of Order) (8:03) by Mathispower4u.     Watch  Second order linear ODEs (45:12) for a lecture on section 2.1.     Do  Subsection 2.1.1: Exercises 2.1.2, 2.1.3, 2.1.4, 2.1.5, 2.1.7 .    Try these additional questions. If necessary, use AI to guide your thinking.   Define by . Let and .    Compute .    Compute .    Compute .    How does your answer to (c) compare to the sum of your answers to (a) and (b)? Is linear?      Consider the differential equation Define the operator by .    Show that and both solve the differential equation by computing and .    For any constants and , compute the value of .    Does solve the differential equation?      Consider the differential equation .    Are and linearly dependent or linearly independent? How do you know?    Describe the general solution to this DE. That is, describe every solution to this DE.          Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Use linearity to verify that a linear combination of solutions to a homogeneous equation is again a solution.    Explain the operator viewpoint and how linear operators encode the structure of ODEs.    Interpret the existence and uniqueness theorem in the context of second‑order linear ODEs.     "
},
{
  "id": "ch-Textbook-10",
  "level": "1",
  "url": "ch-Textbook-10.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 2.2 - Constant Coefficient Second Order ODEs",
  "body": " Daily Prep 2.2 - Constant Coefficient Second Order ODEs   Overview  In this section, we learn how to solve homogeneous second‑order linear differential equations with constant coefficients by assuming exponential solutions and reducing the problem to solving a characteristic quadratic equation. Depending on whether the quadratic has distinct real roots, repeated roots, or complex roots, we will see how each case leads to a different form of the general solution. This method provides a unified and efficient way to analyze many physical systems, setting the stage for deeper exploration of applied models in later sections.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Recognize when a differential equation is a second‑order linear ODE with constant coefficients .    Use the exponential ansatz  to derive the characteristic equation.    Classify solutions according to whether the characteristic equation has distinct real roots, repeated roots, or complex roots.      Learn!  Complete the actions listed below.     Watch video Video 2.2.1: Constant Coefficients (Distinct Roots) by Trevor Bazett.    (Optional) Watch  Solve 2nd Order Linear Homogeneous ODEs with Constant Coefficients (8:23) by Mathispower4u.    (Optional) Watch  Linear Second Order Homogeneous Differential Equations (two distinct real roots) (7:22) by Mathispower4u.    (Optional) Watch  Ex 1: Solve a Linear Second Order Homogeneous Differential Equation Initial Value Problem (7:12) by Mathispower4u.     Read  Subsection 2.2.1: Solving constant coefficient equations .     Watch video Video 2.2.2: The Constant Coefficient Method (all cases) by Trevor Bazett.    (Optional) Watch  Linear Second Order Homogeneous Differential Equations (two real equal roots) (9:09) by Mathispower4u.     Read  Subsection 2.2.2: Complex numbers and Euler’s formula .    (Optional) Watch  Linear Second Order Homogeneous Differential Equations (complex roots) (8:58) by Mathispower4u.    (Optional) Watch  Ex: Solve a Linear Second Order Homogeneous Differential Equation Initial Value Problem (complex) (8:49) by Mathispower4u.     Read  Subsection 2.2.3: Complex roots .     Watch  Constant Coefficient Second Order Linear ODEs, part 1 (17:30) for a lecture on section 2.2.     Watch  Constant Coefficient Second Order Linear ODEs, part 2 (25:21) for a lecture on section 2.2.     Do  Subsection 2.2.4: Exercises 2.2.1, 2.2.2, 2.2.4, 2.2.6, 2.2.7 2.2.8, 2.2.13, 2.2.18 .    Try these additional questions. If necessary, use AI to guide your thinking.    Consider the IVP     Show that solves the differential equation.    Verify that and solve the associated homogeneous equation.    Use (a) and (b) to find a solution to the given IVP.      Find the general solution to .    Construct an equation such that is the general solution.       Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Construct the full general solution for each root type and understand why these functions are linearly independent.    Apply initial conditions to solve for unknown constants using algebraic or matrix methods.    Interpret the mathematical structure of solutions in applications such as mechanical or electrical systems, building intuition for later modeling chapters.     "
},
{
  "id": "ch-Textbook-11",
  "level": "1",
  "url": "ch-Textbook-11.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 2.3 - Higher Order Linear ODEs",
  "body": " Daily Prep 2.3 - Higher Order Linear ODEs   Overview  In this section, we introduce the theory of higher‑order linear homogeneous differential equations , extending familiar second‑order ideas to the general th‑order case. We learn that while most real‑world models are second order, the same foundational principles—linearity, superposition, and linear independence—carry over directly to higher order. The section emphasizes how solutions are built from sets of linearly independent functions and introduces the Wronskian as a computational tool for verifying independence, preparing us to analyze more complex systems using methods that generalize the second‑order theory.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Understand the general form of an th‑order linear homogeneous ODE and how it extends the second‑order case.    Recognize the role of linear independence in constructing general solutions involving fundamental functions.    Learn the definition and purpose of the Wronskian as a test for linear independence.      Learn!  Complete the actions listed below.     Read  Section 2.3 Introduction: Higher order linear ODEs .     Watch  Video 2.3.1: Linear Independence by Trevor Bazett.    (Optional) Watch video Introduction to Higher Order Linear Differential Equations (7:44) by Mathispower4u.     Read  Subsection 2.3.1: Linear independence .    (Optional) Watch video Determine if Four Functions are Linearly Independent or Linearly Dependent (3:42) by Mathispower4u.     Watch  Video 2.3.2: Theory of Higher Order ODEs by Trevor Bazett.     Read  Subsection 2.3.2: Theory of Higher Order ODEs .     Watch  Video 2.3.3: Higher Order Constant Coefficient ODEs by Trevor Bazett.     Read  Subsection 2.3.3: Constant coefficient higher order ODEs .    (Optional) Watch  Intro to Higher Order Linear Homogeneous Differential Equations with Constant Coefficients (7:29) by Mathispower4u.    (Optional) Watch  Solving the Linear Equations L(y)=0 (19:47) from MIT OpenCourseWare. This is Herbert Gross. Black and white video and old school!     Watch  Higher Order Linear ODEs (36:16) for a lecture on section 2.3.     Do  Subsection 2.3.4: Exercises 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.3.6, 2.3.7, 2.3.9, 2.3.13, 2.3.14 .    Try these additional questions. If necessary, use AI to guide your thinking.    Find the general solution to     Find the general solution to . Hint : The characteristic equation factors as .    Find the general solution to . Hint : The characteristic equation factors as .       Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Apply the Wronskian to determine whether a given set of functions forms a fundamental solution set on an interval.    Analyze how computational challenges increase when moving from second‑order equations to higher‑order equations and compare available solution methods.    Relate higher‑order ODE theory to system‑based methods (e.g., rewriting higher‑order equations as first‑order systems) as referenced later in the text.     "
},
{
  "id": "ch-Textbook-12",
  "level": "1",
  "url": "ch-Textbook-12.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 2.4 - Mechanical Vibrations",
  "body": " Daily Prep 2.4 - Mechanical Vibrations   Overview  In this section, we explore how second‑order linear constant‑coefficient differential equations model real‑world physical systems, especially mechanical vibrations. The text introduces the mass‑spring‑damper system, explains how forces such as stiffness, damping, and external inputs shape the motion, and shows how Newton’s laws lead naturally to differential equations of the form . We then see how similar mathematical structures appear in electrical RLC circuits and pendulum motion, highlighting the unifying theme that diverse physical phenomena can be modeled and analyzed using the same ODE framework.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Identify how mass–spring–damper systems give rise to second‑order linear constant‑coefficient ODEs.    Distinguish between forced\/unforced and damped\/undamped motions in mechanical systems.    Recognize that electrical RLC circuits follow the same mathematical form as mechanical vibration models.      Learn!  Complete the actions listed below.     Read  Subsection 2.4.1: Some examples .     Watch  Video 2.4.1: Frictionless Mechanical Vibrations (8:02) by Trevor Bazett.    (Optional) Watch video Introduction to Mechanical Vibrations and Related Applications (6:39) by Mathispower4u.     Read  Subsection 2.4.2: Free undamped motion .    (Optional) Watch video Introduction to Free Undamped Motion (6:56) by Mathispower4u.     Watch  Video 2.4.2: Damped Mechanical Vibrations (10:41) by Trevor Bazett.     Watch  Introduction to Free Damped Motion: Overdamping, Critical Damping, and Underdamping (6:38) by Mathispower4u.     Read  Subsection 2.4.3: Free damped motion .     Watch  Introduction to Free Undamped Motion (Spring System) (10:57) by Mathispower4u.    (Optional) Watch  Ex 1: Undamped Motion IVP Problem (Spring System) (9:31) by Mathispower4u.     Watch  Mechanical Vibrations, part 1: free undamped motion (40:22) and Mechanical Vibrations, part 2: free damped motion (40:22) for a lecture on section 2.4.     Do  Subsection 2.4.4: Exercises 2.4.3, 2.4.6 .    Try these additional questions. If necessary, use AI to guide your thinking.    Consider the spring-mass system shown below. Here, an object of mass is attached to a spring which exerts a linear restorative force with spring constant . Assume also a damping coefficient (perhaps due to friction). Then, if denotes the displacement from equilibrium , we have    A dashpot.   A mass–spring–dashpot system: a wall on the left is connected to a zig‑zag spring, which is attached to a rectangular block labeled “m”; on the right side of the block a rod connects to a dashpot (damper) attached to another wall.    Note: A dashpot is a device (like a shock absorber) designed to exert a resistive force proportional to the velocity of the object. We study the different types of solutions which depend on the values of , and .     Undamped Motion. Suppose there is no friction or other damping factors (i.e. no dashpot). Then in equation  above. That is, . Since , define .     Determine a characteristic equation and roots for the resulting DE (when ).    Find a general solution to the DE. Try to state it in terms of rather than and .        Undamped Motion. A body with mass kilogram is attached to the end of a spring that is stretched 2 meters by a force of 100 newtons. It is set in motion with initial position meter and initial velocity meters per second.     Determine the value of the spring constant and the resulting DE that guides the motion of the mass.    Describe a DE that governs the motion of the mass.    Describe in words the meaning of these initial conditions.    With , the solution to this IVP is . This means the mass will oscillate (simple harmonic motion) with frequency  (measured in hertz; cycles per second). What is the frequency ? What is the period  ?    A solution in the form can be written into the more useful amplitude-phase form  where the amplitude  and the phase shift  .      . Determine the value of .     . Estimate the value of . [Careful: is in the fourth quadrant.]       The first peak in the graph of occurs at (called the time lag . Determine the time lag for the solution to this problem and sketch a graph of the motion .     With damping ( ), in equation  , we investigate the characteristic roots of . These are We have three cases:     Overdamped.  two distinct real roots.     Critically damped.  one repeated real root.     Underdamped.  two complex conjugate roots.       Overdamped Motion. If , the value of is relatively large and we are dealing with strong resistance in comparison to a relatively weak spring or a small mass. Note also that      The two (real, distinct) roots and solve . Explain why these roots are both negative.    Give a general solution to the DE     Compute .        Critically Damped Motion. Here, .     Explain why the one (real, repeated) root to is . Why this root is negative?    Give a general solution to the DE     Compute .        Underdamped Motion. If , the value of is relatively small and we are dealing with very little resistance in comparison to a relatively strong spring or a large mass. For example, suppose , , and .     The roots to the characteristic equation complex. What are they?    Given initial conditions of and , the solution to the DE is Compute . What does the plot of look like?            Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Analyze how changing parameters  affects system behavior, including oscillations and decay rates.    Translate physical laws (Newton’s second law or Kirchhoff’s laws) into corresponding differential equations for mechanical and electrical systems.    Extend the vibration framework to approximate models such as pendulum motion and interpret when linearization is appropriate.     "
},
{
  "id": "SpringMass4",
  "level": "2",
  "url": "ch-Textbook-12.html#SpringMass4",
  "type": "Figure",
  "number": "12",
  "title": "",
  "body": " A dashpot.   A mass–spring–dashpot system: a wall on the left is connected to a zig‑zag spring, which is attached to a rectangular block labeled “m”; on the right side of the block a rod connects to a dashpot (damper) attached to another wall.   "
},
{
  "id": "sec-Toprepareforclass24-3-13-2-1-4",
  "level": "2",
  "url": "ch-Textbook-12.html#sec-Toprepareforclass24-3-13-2-1-4",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "dashpot "
},
{
  "id": "sec-Toprepareforclass24-3-13-2-1-5-2-2",
  "level": "2",
  "url": "ch-Textbook-12.html#sec-Toprepareforclass24-3-13-2-1-5-2-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "frequency period amplitude-phase form amplitude phase shift time lag "
},
{
  "id": "sec-Toprepareforclass24-3-13-2-1-5-2-3",
  "level": "2",
  "url": "ch-Textbook-12.html#sec-Toprepareforclass24-3-13-2-1-5-2-3",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "damping "
},
{
  "id": "sec-Toprepareforclass24-3-13-2-1-5-2-4-1-1",
  "level": "2",
  "url": "ch-Textbook-12.html#sec-Toprepareforclass24-3-13-2-1-5-2-4-1-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Overdamped. "
},
{
  "id": "sec-Toprepareforclass24-3-13-2-1-5-2-4-2-1",
  "level": "2",
  "url": "ch-Textbook-12.html#sec-Toprepareforclass24-3-13-2-1-5-2-4-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Critically damped. "
},
{
  "id": "sec-Toprepareforclass24-3-13-2-1-5-2-4-3-1",
  "level": "2",
  "url": "ch-Textbook-12.html#sec-Toprepareforclass24-3-13-2-1-5-2-4-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Underdamped. "
},
{
  "id": "sec-Toprepareforclass24-3-13-2-1-5-3-1",
  "level": "2",
  "url": "ch-Textbook-12.html#sec-Toprepareforclass24-3-13-2-1-5-3-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Overdamped Motion. "
},
{
  "id": "sec-Toprepareforclass24-3-13-2-1-5-4-1",
  "level": "2",
  "url": "ch-Textbook-12.html#sec-Toprepareforclass24-3-13-2-1-5-4-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Critically Damped Motion. "
},
{
  "id": "sec-Toprepareforclass24-3-13-2-1-5-5-1",
  "level": "2",
  "url": "ch-Textbook-12.html#sec-Toprepareforclass24-3-13-2-1-5-5-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "Underdamped Motion. "
},
{
  "id": "ch-Textbook-13",
  "level": "1",
  "url": "ch-Textbook-13.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 2.5 - Nonhomogeneous Equations",
  "body": " Daily Prep 2.5 - Nonhomogeneous Equations   Overview  In this section, we learn how to solve nonhomogeneous linear differential equations by building on our knowledge of homogeneous equations. The core idea is that the general solution to a nonhomogeneous equation is obtained by adding any particular solution to the complementary (homogeneous) solution. We then explore why any two particular solutions differ by a homogeneous solution, and introduce the method of undetermined coefficients as a practical way to guess particular solutions when the forcing function has a familiar algebraic form.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Understand the structure of a nonhomogeneous linear ODE and how it relates to its associated homogeneous equation.    Explain why the general solution is the sum of the complementary solution and any particular solution.    Recognize when the method of undetermined coefficients can be used to guess a particular solution.      Learn!  Complete the actions listed below.     Watch  Video 2.5.1: Solving Nonhomogeneous Equations using Undetermined Coefficients (12:25) by Trevor Bazett.     Read  Subsection 2.5.1: Solving nonhomogeneous equations .    (Optional) Watch video Prove the Form of he General Solution to a Linear Second Order Nonhomogeneous DE (7:32) by Mathispower4u.     Read  Subsection 2.5.2: Undetermined coefficients .    (Optional) Watch video The Form of the Particular Solution Using the Method of Undetermined Coefficients - Part 1 (7:25) by Mathispower4u.    (Optional) Watch video The Form of the Particular Solution Using the Method of Undetermined Coefficients - Part 2 (9:14) by Mathispower4u.    (Optional) Watch video Method of Undetermine Coefficients to Find a Particular Solution (trig) (9:23) by Mathispower4u.    (Optional) Watch  Ex 1: Method of Undetermined Coefficients to Find the the General Solution (exponential) (7:03) by Mathispower4u.    (Optional) Watch  Ex 2: Method of Undetermined Coefficients to Find the the General Solution (quadratic) (10:08) by Mathispower4u.    (Optional) Watch  Find a General Solution to a Nonhomogeneous DE Using Undetermined Coefficients (repeat term) (9:48) by Mathispower4u.     Read  Subsection 2.5.3: Variation of parameters .     Watch  Derive the Variation of Parameters Formula to Solve Linear Second Order Nonhomogeneous DEs (6:59) by Mathispower4u.    (Optional) Watch  Ex 1: General Solution to a Second Order DE Using Variation of Parameters (8:26) by Mathispower4u.     Watch  Nonhomogeneous Equations, part 1: Undetermined Coefficients (30:41) and Nonhomogeneous Equations, part 2: Variation of Parameters (17:33) for a lecture on section 2.5.     Do  Subsection 2.5.4: Exercises 2.5.1, 2.5.5, 2.5.7, 2.5.8, 2.5.9 .    Try these additional questions. If necessary, use AI to guide your thinking.    Respond to the following questions about the reading.     is called a complementary solution . What do you think it complements?    In your own words, summarize Theorem 2.5.1 .     Subsection 2.5.2 , on Undetermined Coefficients, mentions a hiccup . In a sentence or two, what is this hiccup? Can it be managed? If so, how?    Give an example of a second-order, linear, constant-coefficient, nonhomogeneous ODE for which Undetermined Coefficients will not work.      Find a particular solution of  Note: A first guess might be . However, the presence of on the left-hand side, signals that we probably need a term involving as well. So try .    Suppose we wish to find a particular solution to If we try , we find that no matter how the value of is chosen. Using a trial solution in which we multiple by , find a particular solution to .       Determine the appropriate form for a particular solution of     Determine the coefficients in the particular solution you guessed in (a). Use a computer algebra system such as Wolfram Alpha if you wish to do less algebra.       Find a particular solution of .    Solve the initial value problem for , .       Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Demonstrate, using operator notation, why any two particular solutions differ by a solution to the homogeneous equation.    Construct appropriate ansatz forms for particular solutions in polynomial forcing cases and justify parameter choices.    Analyze how different methods (guessing, undetermined coefficients, or other techniques) can yield equivalent general solutions despite producing different intermediate formulas.     "
},
{
  "id": "ch-Textbook-14",
  "level": "1",
  "url": "ch-Textbook-14.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 3.1 - The Laplace Transform",
  "body": " Daily Prep 3.1 - The Laplace Transform   Overview  In this section, we introduce the Laplace transform as a powerful method for solving differential equations by converting them into algebraic equations. We explain how the transform takes a function of time and produces a new function of a frequency-like variable , allowing difficult ODEs to become simpler algebraic expressions that can be solved and then inverted. We also see motivating examples, including its usefulness for handling discontinuous inputs and modeling physical systems such as forced oscillators and electrical circuits.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Understand the definition of the Laplace transform and how it converts a time-domain function into an -domain function.    Explain how solving ODEs becomes easier by transforming them into algebraic equations.    Recognize common Laplace transforms through simple examples such as constants and exponentials.      Learn!  Complete the actions listed below.     Watch  Video 3.1.1: Intro to Laplace Transform (11:52) by Trevor Bazett.     Read  Subsection 3.1.1: The transform .     Watch  Video 3.1.2: Linearity, Existence, and Inverses of the Laplace Transform (7:14) by Trevor Bazett.    (Optional) Watch video Introduction to The Laplace Transform (8:31) by Mathispower4u.    (Optional) Watch video Introduction Laplace Transforms (3:47) by Mathispower4u.    (Optional) Watch video The Laplace Transform of the Unit Step Function (3:50) by Mathispower4u.     Read  Subsection 3.1.2: Existence and uniqueness .     Watch video The Existence and Uniqueness of a Laplace Transform (5:34) by Mathispower4u.     Watch video Introduction to Inverse Laplace Transforms (8:56) by Mathispower4u.     Read  Subsection 3.1.3: The inverse transform .     Watch  Video 3.1.3: Translation and Inverse Laplace Transforms of Irreducible Factors (12:10) by Trevor Bazett.     Watch  Video 3.1.4: Inverse Laplace Transform with Repeated Factors (8:29) by Trevor Bazett.     Watch  Find Basic Inverse Laplace Transforms (5:04) by Mathispower4u.    (Optional) Watch  Laplace Transforms (38:34) from MIT OpenCourseWare. This is Herbert Gross. Black and white video and old school but still quite good!    For an absolutely beautiful and insightful introduction to the subject via MIT, watch  MIT 18.03 Differential Equations, Spring 2006 (47:40) . The basic idea of this transform is to replace a DE with an algebraic equation, solve the algebraic equation, and then transform back to identify a solution. It is particularly useful when solving IVPs having discontinuous terms.    (Optional) Watch  Laplace Transform, part 1 (34:15) and Laplace Transform, part 2 (24:32) for a lecture on section 3.1.     Do  Subsection 3.1.4: Exercises 3.1.5, 3.1.7, 3.1.9, 3.1.10, 3.1.12, 3.1.14, 3.1.15, 3.1.16, 3.1.19 .    Try these additional questions. If necessary, use AI to guide your thinking.    If is defined for , then its Laplace transform is defined by .    Draw a graph of the functions from Example 3.1.4 .    In your own words, what does it mean for a function to be of exponential order ?    Suppose on . Compute . What is the domain of ? [Try not using Example 3.1.1 as a crutch.]    Suppose on . Compute . What is the domain of ?    Using a table of Laplace transforms ( Table 3.1 ), compute   What is the domain of ? Hint:  .    The unit step function is defined by     Graph the unit step function, .    Define . Write as a piecewise-defined function and graph it.    Compute .      Compute the inverse Laplace transform of by hand, using partial fractions and tables. Does AI agree with your result?    Compute the inverse Laplace transform of using partial fractions and tables. Does AI agree with your result?    Use the definition of Laplace transform to compute for the function graphed in .  Function .   A graph of a piecewise function f(t). For t less than 1, the function equals 0, shown by a horizontal line on the t-axis with a filled dot at t = 0 and an open circle at t = 1. For t greater than or equal to 1, the function increases linearly, passing through the points (1, 1) and (2, 2), and continues upward with an arrow.        Use the definition of Laplace transform to compute for the function graphed in .  Function .   A graph of a piecewise function g(t). Along the t‑axis, the function is 0 from the origin up to t=a, shown by a horizontal line with a filled dot at t=0 and an open circle at t=a. From t=a to t=b, the function jumps to a constant value c, represented by a horizontal line at height c, with a filled dot at t=a and an open circle at t=b. For t greater than b, the function returns to 0, indicated by a horizontal line on the t‑axis starting at a filled dot at t=b and extending to the right with an arrow.        Find the inverse Laplace transform of .       Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Interpret the Laplace transform as moving between time and frequency domains, especially for systems governed by equations like .    Analyze why the Laplace method handles discontinuities and piecewise-defined inputs effectively.    Apply the Laplace transform framework to understand applications in areas such as signal processing, electrical circuits, and physical modeling.     "
},
{
  "id": "GraphLaplaceTransformA",
  "level": "2",
  "url": "ch-Textbook-14.html#GraphLaplaceTransformA",
  "type": "Figure",
  "number": "13",
  "title": "",
  "body": " Function .   A graph of a piecewise function f(t). For t less than 1, the function equals 0, shown by a horizontal line on the t-axis with a filled dot at t = 0 and an open circle at t = 1. For t greater than or equal to 1, the function increases linearly, passing through the points (1, 1) and (2, 2), and continues upward with an arrow.    "
},
{
  "id": "GraphLaplaceTransformB",
  "level": "2",
  "url": "ch-Textbook-14.html#GraphLaplaceTransformB",
  "type": "Figure",
  "number": "14",
  "title": "",
  "body": " Function .   A graph of a piecewise function g(t). Along the t‑axis, the function is 0 from the origin up to t=a, shown by a horizontal line with a filled dot at t=0 and an open circle at t=a. From t=a to t=b, the function jumps to a constant value c, represented by a horizontal line at height c, with a filled dot at t=a and an open circle at t=b. For t greater than b, the function returns to 0, indicated by a horizontal line on the t‑axis starting at a filled dot at t=b and extending to the right with an arrow.    "
},
{
  "id": "ch-Textbook-15",
  "level": "1",
  "url": "ch-Textbook-15.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 3.2 - Transforms of Derivatives and ODEs",
  "body": " Daily Prep 3.2 - Transforms of Derivatives and ODEs   Overview  In this section, we learn how the Laplace transform interacts with derivatives and how this property becomes the key tool for solving ordinary differential equations in the -domain. The text shows that differentiation in time becomes multiplication by (with corrections coming from initial conditions), and provides a table of Laplace transforms for first, second, and third derivatives. Students then see how this framework converts an ODE into an algebraic equation, which can be solved for the transformed function and inverted to obtain the solution in the time domain.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Understand how the Laplace transform handles derivatives, including the formulas for first, second, and third derivatives.    Recognize that taking the Laplace transform of an ODE converts it into an algebraic equation in .    Learn how initial conditions appear naturally in the transformed equation.      Learn!  Complete the actions listed below.     Watch  Video 3.2.1: Transforms of Derivatives and integrals (7:47) by Trevor Bazett.     Read  Subsection 3.2.1: Transforms of derivatives .     Watch  Video 3.2.3: Solving an ODE using Laplace Transforms Example (7:31) by Trevor Bazett.     Watch  Video 3.2.2: How to solve ODEs with the Laplace Transform by Trevor Bazett.     Read  Subsection 3.2.2: Solving ODEs with the Laplace transform .    (Optional) Watch video Laplace Transforms of Derivatives \/ Using Laplace Transforms to Solve Differential Equations (8:51) by Mathispower4u.     Watch  Video 3.2.4: The Laplace Transform of Piecewise Functions (11:20) by Trevor Bazett.     Read  Subsection 3.2.3: Using the Heaviside function .     Watch  Video 3.2.5: Solving an IVP with a piecewise nonhomogeneity (10:13) by Trevor Bazett.    (Optional) Watch video Laplace Transforms: Solving Differential Equations containing Heaviside Functions (9:27) by Mathispower4u.     Read  Subsection 3.2.4: Transfer functions .    (Optional) Watch  Laplace Transforms: Determining a Transfer Function (4:41) by Mathispower4u.     Read  Subsection 3.2.5: Transforms of integrals .    (Optional) Watch  Laplace Transforms of Integrals (5:34) by Mathispower4u.    (Optional) Watch  Transforms of Derivatives and ODEs, part 1 (29:43) and Transforms of Derivatives and ODEs, part 2 (21:35) for a lecture on section 3.2.     Do  Subsection 3.2.6: Exercises 3.2.2, 3.2.4, 3.2.13, 3.2.18, 3.2.20 .    Try these additional questions. If necessary, use AI to guide your thinking.    What is the next line in Table 3.2.1 ?     Plot the following functions mentioned in the text.                      Using the Laplace transform, solve the IVP     Consider the IVP Solve using the Laplace transform.    (Shifting Theorem) Suppose for . For any real number and ,     We know that . Compute .    Define Compute the Laplace transform . Hint: Write .    Solve the IVP where     A mass that weighs 32 lb ( ) is attached to the free end of a spring that is stretched 1 ft by a force of 4 lb ( lb\/ft). The mass is initially at rest in its equilibrium position. Beginning at time (seconds), an external force is applied to the mass-spring system, but at time this force is turned off (abruptly) and the mass is allowed to continue its motion unimpeded. [Assume no friction (i.e. dashpot).] Find the resulting position function of the mass.   A dashpot.   A mass–spring–dashpot system: a wall on the left is connected to a zig‑zag spring, which is attached to a rectangular block labeled “m”; on the right side of the block a rod connects to a dashpot (damper) attached to another wall.      Use the definition of Laplace transform to compute (by hand) for the function graphed in .   Function .   A graph of a function f(t). The function is 0 up to t=1, shown by a horizontal line on the t‑axis ending at a filled dot at t=1. From that point, the graph rises linearly, passing through the point (2,2), and continues upward to the right with an arrow.     Use technology to verify this result.    Use partial fractions to evaluate by hand. Use technology to verify the result.    Keeping the result of the above problem in mind, solve (by hand) the IVP using the Laplace transform. Verify the result using appropriate technology.       Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Apply the full set of derivative-transform formulas to solve higher‑order linear ODEs with given initial conditions.    Use algebraic manipulation in the -domain—including partial fractions—to prepare expressions for inverse Laplace transforms.    Interpret the Laplace‑domain solution in terms of the structure of the original differential equation, including forced responses and natural modes.     "
},
{
  "id": "SpringMass4b",
  "level": "2",
  "url": "ch-Textbook-15.html#SpringMass4b",
  "type": "Figure",
  "number": "15",
  "title": "",
  "body": " A dashpot.   A mass–spring–dashpot system: a wall on the left is connected to a zig‑zag spring, which is attached to a rectangular block labeled “m”; on the right side of the block a rod connects to a dashpot (damper) attached to another wall.   "
},
{
  "id": "GraphLaplaceTransformC",
  "level": "2",
  "url": "ch-Textbook-15.html#GraphLaplaceTransformC",
  "type": "Figure",
  "number": "16",
  "title": "",
  "body": " Function .   A graph of a function f(t). The function is 0 up to t=1, shown by a horizontal line on the t‑axis ending at a filled dot at t=1. From that point, the graph rises linearly, passing through the point (2,2), and continues upward to the right with an arrow.    "
},
{
  "id": "ch-Textbook-16",
  "level": "1",
  "url": "ch-Textbook-16.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 3.3 - Convolution",
  "body": " Daily Prep 3.3 - Convolution   Overview  In this section we learn about the convolution of two functions, a construction that lets us combine functions in a way that behaves very much like a product while being compatible with the Laplace transform. The section introduces the definition of convolution as an integral from 0 to , works through examples such as convolving exponentials or trigonometric functions, and highlights key algebraic properties including commutativity and associativity. Most importantly, we will see that the Laplace transform of a convolution is the product of the individual Laplace transforms, a fact that allows us to compute inverse Laplace transforms and solve differential equations involving general forcing functions.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Understand the definition of the convolution  .    Compute simple convolutions using integration techniques such as integration by parts.    Recognize and apply the basic algebraic properties of convolution (commutativity, scalar multiplication, associativity).      Learn!  Complete the actions listed below.     Watch  Video 3.3.1: Convolutions (10:31) by Trevor Bazett.    (Optional) Watch video Intro to the Convolution and Using the Convolution to Find an Inverse Laplace Transform (10:56) by Mathispower4u.     Read  Subsection 3.3.1: The convolution .    (Optional) Watch video Find the Convolution of Two Functions (Integration by Parts Twice) (5:47) by Mathispower4u.    (Optional) Watch  Introduction to Using a Convolution to Solve an Initial Value Problem (5:58) by Mathispower4u.     Read  Subsection 3.3.2: Solving ODEs .    (Optional) Watch  Solve an Initial Value Problem Using Convolution (4:51) by Mathispower4u.    (Optional) Watch  Solving a Volterra Integral Equation (5:58) by Mathispower4u.     Read  Subsection 3.3.3: Volterra integral equation .    (Optional) Watch  Convolution (18:46) for a lecture on section 3.3.    (Optional) Watch  Using the Convolution Theorem to Do Laplace Transforms (18:09) from Math Al lDay by Dr. George Sweeney.     Do  Subsection 3.3.4: Exercises 3.3.1, 3.3.3, 3.3.7, 3.3.14, 3.3.16 .    Try these additional questions. If necessary, use AI to guide your thinking.     Theorem 3.3.1 sheds light on why we care to bother defining the convolution. In your own words, describe the purpose of defining a convolution product.    Let for , and . Compute the convolution product .     Solve the Volterra Integral Equation         Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Use the convolution theorem to compute inverse Laplace transforms.    Apply convolution to solve linear ODEs with general forcing functions expressed through Laplace transforms.    Decompose rational expressions into Laplace-transformable factors and interpret solutions as convolutions of known functions.     "
},
{
  "id": "ch-Textbook-16-2-2",
  "level": "2",
  "url": "ch-Textbook-16.html#ch-Textbook-16-2-2",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "convolution "
},
{
  "id": "ch-Textbook-17",
  "level": "1",
  "url": "ch-Textbook-17.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 3.4 - Dirac Delta and Impulse Response",
  "body": " Daily Prep 3.4 - Dirac Delta and Impulse Response   Overview  In this section we explore the idea of modeling instantaneous “impulses” using the Dirac delta, a generalized function that concentrates all its mass at a single point. The section begins by examining short rectangular pulses and their Laplace transforms, then shows how letting the pulse width approach zero leads to the definition of the delta function, an object meaningful only under an integral sign. You will learn how captures the effect of a sudden input—analogous to striking a system with a hammer—and how its Laplace transform allows us to analyze impulse responses of differential‑equation models.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Understand how a short rectangular pulse is defined and how its Laplace transform is computed.    Explain why the Dirac delta is not a classical function but a generalized function defined via integrals.    Recognize that the delta function represents a unit‑mass impulse concentrated at a single point in time.      Learn!  Complete the actions listed below.     Watch  Video 3.4.1: The Delta Function (9:25) by Trevor Bazett.     Read  Subsection 3.4.1: Rectangular pulse .     Read  Subsection 3.4.2: The delta function .    (Optional) Watch video Dirac Delta Function (17:47) from Khan Academy.     Read  Subsection 3.4.3: Impulse response .     Watch  Video 3.4.2: Laplace Transform of Periodic Functions (7:48) by Trevor Bazett.     Watch  Video 3.4.3: The Laplace Transform of IVPs with Periodic Delta Functions (10:19) by Trevor Bazett.     Read  Subsection 3.4.3: Impulse response .     Do  Subsection 3.4.6: Exercises 3.4.1, 3.4.2, 3.4.4, 3.4.8 .    Try these additional questions. If necessary, use AI to guide your thinking.    Sometimes the dirac delta function of section 3.4 is called a distribution. Which terminology do you prefer and why?    Solve (find the impulse response) , , .       Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Use limits of shrinking rectangular pulses to justify the formal properties of .    Apply the Laplace transform of the Dirac delta to solve differential equations with impulsive forcing.    Interpret impulse responses to understand how a system reacts to instantaneous inputs and generalize this to more complex inputs.     "
},
{
  "id": "ch-Textbook-17-3-3-2-1",
  "level": "2",
  "url": "ch-Textbook-17.html#ch-Textbook-17-3-3-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "generalized function "
},
{
  "id": "ch-Textbook-18",
  "level": "1",
  "url": "ch-Textbook-18.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 4.1 - Vectors, Mappings, and Matrices",
  "body": " Daily Prep 4.1 - Vectors, Mappings, and Matrices   Overview  In this section we will learn how vectors, linear mappings, and matrices provide a systematic way to organize and solve problems involving many variables. The text motivates linear algebra by showing how even simple systems of equations generalize to high‑dimensional settings, where matrices and vector operations become essential tools. You will explore n‑dimensional space, interpret vectors as geometric arrows, and see how linear equations, functions, and differential‑equation models all benefit from a unified matrix‑based framework.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Understand vectors as n‑tuples representing points or arrows in n‑dimensional space.    Recognize how systems of linear equations can be organized and solved more systematically using matrices .    Interpret basic vector operations such as addition and scalar multiplication .      Learn!  Complete the actions listed below.    (Optional) Watch  What is a Vector? (4:40) by David Huynh.     Read  Subsection A.1.1: Vectors and operations on vectors .    (Optional) Do interact with the applet Adding Vectors Geometrically by Tim Brzezinski.    (Optional) Do interact with the applet Scalar Multiplication by Peter Sassman.    (Optional) Watch  Linear Transformations and Matrices (10:58) by 3Blue1Brown.     Read  Subsection A.1.2: Linear mappings and matrices .    (Optional) Watch video Linear Tranformations on Vector Spaces (9:10) by Professor Dave Explains.     Do  Subsection A.1.3: Exercises A.1.1, A.1.3, A.1.4, A.1.5, A.1.6, A.1.7, A.1.8, A.1.10, A.1.11 .    Try these additional questions. If necessary, use AI to guide your thinking.    In your own words, describe what a linear operator is.    Give another word for magnitude (as it pertains to vectors).     Here the author makes a completely false statement in the text: The reason these are called a basis is that every other vector can be written as a linear combination of them. Use AI or do a Google search on `basis', `linearly independent', and `span' and attempt to explain what is wrong with this sentence in the textbook.     At one point in the reading , the author states: Hence, we may think of matrices being linear mappings, and linear mappings being matrices. . He is quick to correct this. Thinking of the linear mapping , do you see why? Extra Credit: Can you describe an infinite-dimensional matrix that could represent for smooth functions ? Hint: Think Taylor series.     Label the vectors , , and in .   Vectors and .   A 2‑dimensional coordinate plot showing three arrows (vectors) originating from the origin. Each arrow points to a different point in the plane. The endpoints of the three arrows are connected with light line segments, forming a triangular shape. The horizontal axis is labeled x1x_1x1​ and the vertical axis is labeled x2x_2x2​. Tick marks along the axes show values from 1 to 4.       Let . Express , , and on the graph.   Sketch vectors , , and on the graph.   A square grid covering the region from −2 to 2 on the horizontal axis labeled x1​ and from −3 to 4 on the vertical axis labeled x2​. The grid lines form evenly spaced horizontal and vertical lines. The axes intersect at the origin, which is centered in the image. Tick marks along both axes show integer values.      Let and . Express each of the following as a linear combination of and .   An interesting grid for plotting vectors.   A coordinate plane labeled x1​ horizontally and x2​ vertically, extending from −8 to 8 on both axes. The grid is overlaid with a series of diagonal, evenly spaced parallel lines slanting upward from left to right, forming a diamond‑shaped lattice pattern across the plane.                       Suppose a linear mapping takes to and it takes to . Write down the matrix representing the mapping .       Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Analyze how linear mappings transform vectors and how these mappings can be represented using matrices.    Apply matrix methods to organize and simplify large systems, including those arising from differential equations.    Develop geometric and algebraic intuition for high‑dimensional vector spaces and the role of linear structure in modeling real‑world problems.     "
},
{
  "id": "sec-Toprepareforclass41-3-9-2-2-1",
  "level": "2",
  "url": "ch-Textbook-18.html#sec-Toprepareforclass41-3-9-2-2-1",
  "type": "Paragraph (with a defined term)",
  "number": "",
  "title": "",
  "body": "magnitude "
},
{
  "id": "ParallelogramRule",
  "level": "2",
  "url": "ch-Textbook-18.html#ParallelogramRule",
  "type": "Figure",
  "number": "17",
  "title": "",
  "body": " Vectors and .   A 2‑dimensional coordinate plot showing three arrows (vectors) originating from the origin. Each arrow points to a different point in the plane. The endpoints of the three arrows are connected with light line segments, forming a triangular shape. The horizontal axis is labeled x1x_1x1​ and the vertical axis is labeled x2x_2x2​. Tick marks along the axes show values from 1 to 4.   "
},
{
  "id": "Vectors1",
  "level": "2",
  "url": "ch-Textbook-18.html#Vectors1",
  "type": "Figure",
  "number": "18",
  "title": "",
  "body": " Sketch vectors , , and on the graph.   A square grid covering the region from −2 to 2 on the horizontal axis labeled x1​ and from −3 to 4 on the vertical axis labeled x2​. The grid lines form evenly spaced horizontal and vertical lines. The axes intersect at the origin, which is centered in the image. Tick marks along both axes show integer values.   "
},
{
  "id": "Vectors2",
  "level": "2",
  "url": "ch-Textbook-18.html#Vectors2",
  "type": "Figure",
  "number": "19",
  "title": "",
  "body": " An interesting grid for plotting vectors.   A coordinate plane labeled x1​ horizontally and x2​ vertically, extending from −8 to 8 on both axes. The grid is overlaid with a series of diagonal, evenly spaced parallel lines slanting upward from left to right, forming a diamond‑shaped lattice pattern across the plane.   "
},
{
  "id": "ch-Textbook-19",
  "level": "1",
  "url": "ch-Textbook-19.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 4.2 - Matrix Algebra",
  "body": " Daily Prep 4.2 - Matrix Algebra   Overview  This section introduces matrix algebra by beginning with the simplest case: 1×1 matrices, which behave just like real numbers under addition, scalar multiplication, and composition. From this starting point, we see how these familiar operations naturally generalize to larger matrices.  We emphasize that matrices represent linear mappings between vector spaces, and that matrix operations—such as addition, scalar multiplication, and composition (matrix multiplication)—are defined so that they behave consistently with the way linear mappings act on vectors.  We learn how to add matrices element‑wise, how scalar multiplication applies uniformly to every entry, and how matrix multiplication corresponds to composing linear transformations. Throughout, concrete numerical examples illustrate how these algebraic rules connect to the action of matrices on vectors and why mismatched matrix sizes make certain operations undefined.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Understand that matrices represent linear mappings and that 1×1 matrices behave like real numbers.    Perform matrix addition and scalar multiplication when matrix sizes match.    Recognize when matrix operations are undefined due to incompatible dimensions.      Learn!  Complete the actions listed below.     Read  Section A.2: Matrix algebra .    (Optional) Do interact with the applet Matrix Addition and Scalar Multiplication by Heather Pierce for practice.    (Optional) Do interact with the applet Multiplying Two Matrices by Mathiyalagan.    (Optional) Watch  Matrix Multiplication as Composition (10:03) by 3Blue1Brown.     Do  Subsection A.2.8: Exercises A.2.2, A.2.3, A.2.4, A.2.5, A.2.103, A.2.105 .    Try these additional questions. If necessary, use AI to guide your thinking.    What is the relationship between dot product and matrix multiplication?    What is the relationship between the product of a matrix and a column vector and the product of matrix with another matrix ?    Are all nonzero matrices invertible? If not, can you give an example?    Define and . Compute and .    Compute where and .    If is and is , then what are the sizes of and ?    Suppose and . Compute .    Use and to demonstrate that can happen.    Let and . Compute , , , and .       Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Explain conceptually how matrix multiplication corresponds to composition of linear mappings.    Analyze examples illustrating how matrix operations affect the resulting action on vectors, using algebraic structure to justify results rather than computation alone.    Relate familiar 1×1 mappings to higher‑dimensional cases and generalize the underlying algebraic principles to arbitrary matrix sizes.     "
},
{
  "id": "ch-Textbook-20",
  "level": "1",
  "url": "ch-Textbook-20.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 4.3 - Elimination",
  "body": " Daily Prep 4.3 - Elimination   Overview  In this section we learn how systems of linear equations can be solved systematically using elimination , a method that rewrites equations in ways that preserve their solutions. You will see how a system can be expressed compactly as a matrix equation , why elimination helps even when the matrix is not invertible or not square, and how a small set of simple operations— swapping equations, scaling equations, and adding multiples of one equation to another— can always be used to reduce a system to a form where solutions can be read off directly. These ideas also motivate the construction of the augmented matrix, which provides a compact way to organize the elimination process and serves as the starting point for many linear-algebra algorithms.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Recognize how a system of linear equations can be written in matrix form as .    Identify the three elementary equation operations: swapping equations, scaling an equation by a nonzero number, and adding a multiple of one equation to another.    Understand the purpose of the augmented matrix as a compact representation of a linear system.      Learn!  Complete the actions listed below.     Read  Subsection A.3.1: Linear systems of equations .    (Optional) Watch  Elementary Row Operations, Row Echelon Form, and Reduced Row Echelon Form (53:47) by Christopher Lum.     Read  Subsection A.3.2: Row echelon form and elementary operations .     Read  Subsection A.3.3: Non-unique solutions and inconsistent systems .    (Optional) Do interact with the applet The Reduced Row Echelon Form of a Matrix by Ewan Kummel to visualize row reduction.    (Optional) Watch  Determining Linear Independence vs Linear Dependence (6:38) by Trevor Bazett.     Read  Subsection A.3.4: Linear independence and rank .    (Optional) Watch  Introduction to Linear Independent and Linearly Dependent Sets of Vectors (8:49) by Mathispower4u.     Read  Subsection A.3.5: Computing the inverse .     Watch  Determining Inverse Matrices Using Augmented Matrices (9:57) by Mathispower4u.    (Optional) Watch  Ex 1: Inverse of a 3x3 Matrix Using an Augmented Matrix (7:09) by Mathispower4u.     Do  Subsection A.3.6: Exercises A.3.1, A.3.2, A.3.5, A.3.8, A.3.101, A.3.102, A.3.103, A.3.104, A.3.105, A.3.108 .    Try these additional questions. If necessary, use AI to guide your thinking.    List the three elementary row operations . What do these row operations preserve?    If a linear system has a free variable , what does that tell you about the solution space?    Is this system consistent? If so, why? If not, why not? This system can be reduced to the triangular form: It can be written in augmented matrix form as     Determine if the system below is consistent. If so, why? If not, why not? The augmented matrix for this system can be row reduced to produce     For what values of will the following system be consistent?     In this exercise, we reduce to row-echelon form (REF) and then to reduced row-echelon form (RREF). State the row operations that do this. Cover the top row and look at the remaining two rows for the left-most nonzero column.  Final step to create the reduced row echelon form: Beginning with the rightmost leading entry, and working upwards to the left, create zeros at each leading entry and scale rows to transform each leading entry into 1.     Identify the pivot columns, the basic variables, and the free variables for the system: which can also be written as     For the linear system we obtain the REF Is this system consistent? If so, identify any free variables and state the number of solutions.    Let and . We determine whether is in the plane spanned by the columns of .   Finish rewriting this question in vector form: Do weights and exists so that...    The corresponding augmented matrix can be put in REF: Is in the plane spanned by the columns of ?       Consider the augmented matrix below.    Write down the corresponding system of equations.    Fill in the missing elements of the corresponding vector equation:     Write this in the form of a matrix equation .       The equation has a solution if and only if is a  of the columns of .    Use the inverse of to solve     Use the augmented matrix below to determine the inverse of , if it exists.        Do MyOpenMath questions from this section.      Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Use elimination logically and systematically to reduce a system to a form where one can read off variables, such as reaching an equation like .    Explain how elimination is connected to finding matrix inverses by solving multiple systems for different right-hand sides.     Analyze how elimination applies even when is non-invertible or non-square, and interpret what this implies about the possible solution sets of the system.      "
},
{
  "id": "ch-Textbook-21",
  "level": "1",
  "url": "ch-Textbook-21.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 4.4 - Subspaces, Dimension, and the Kernel",
  "body": " Daily Prep 4.4 - Subspaces, Dimension, and the Kernel   Overview  This section introduces the idea that certain collections of vectors arising in linear algebra—particularly the set of solutions to a homogeneous linear equation—form what are known as subspaces of . A subspace is any subset closed under vector addition and scalar multiplication, so every linear combination of its vectors remains inside it. The notes show that familiar examples such as , the zero vector alone, or sets like in all satisfy these properties. A subspace can always be described as the span of some set of vectors, and if that spanning set is linearly independent, it forms a basis . The number of basis vectors defines the subspace’s dimension , a quantity that is unique even though many different bases may exist. This viewpoint emphasizes that subspaces behave like smaller Euclidean spaces embedded inside higher-dimensional ones and that vectors in a ‑dimensional subspace can be coordinatized using numbers once a basis is chosen.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Define a subspace and explain the closure properties required for a subset of to be a subspace.    Recognize simple examples of subspaces, including , the zero subspace, and spans of given vectors.    Describe what it means for a set of vectors to form a basis of a subspace.      Learn!  Complete the actions listed below.    (Optional) Watch  Subpsaces are the Natural Subsets of Linear Algebra (6:25) by Trevor Bazett.     Read  Subsection A.4.1: Subspaces, basis, and dimension .     Watch  The Dimension of a Subspace (5:10) by Trevor Bazett.    (Optional) Watch  The Basis of a Subspace (3:52) by Trevor Bazett.     Read  Subsection A.4.2: Kernel .    (Optional) Watch  The Null Space and Column Space of a Matrix (10:40) by Trevor Bazett.    (Optional) Watch  Computing Dimension of Null Space and Column Space (3:26) by Trevor Bazett.    (Optional) Watch  The Dimension Theorem (4:01) by Trevor Bazett.     Do  Subsection A.4.3: Exercises A.3.1, A.3.2, A.3.5, A.3.8, A.3.101, A.3.102, A.3.103, A.3.104, A.3.105, A.3.108 .   Try the exercises below. If necessary, use AI to guide your thinking.    Do MyOpenMath questions from this section.     Exercises   Is this a subspace?   Consider the subset . Is a subspace of ?      Yes.    Correct. is the solution set to the homogeneous linear equation , so it is closed under all linear combinations and therefore is a subspace. (Homogeneous solution sets are kernels of linear maps.)      No, because it is “just” a plane.    Not quite. Planes through the origin defined by a homogeneous linear equation are subspaces; the key property is closure under linear combinations.      No, because it is not all of .    Subspaces need not be the whole space—they just need to contain and be closed under addition and scalar multiplication.      Sets defined as solutions to homogeneous linear equations are kernels of linear maps—kernels are subspaces.     Is this set a subspace?   Consider the subset Does form a subspace of ?      Yes, because the defining equation is linear.    Not quite. Only homogeneous linear equations (right-hand side equal to zero) define subspaces. This plane does not pass through the origin.      No, because the set does not contain the zero vector.    Correct. A subspace must contain and must be closed under all linear combinations. A nonhomogeneous equation such as cannot define a subspace. (The section explains that subspaces arise as solution sets to homogeneous equations—kernels.)      No, because it contains infinitely many points.    Subspaces can be infinite. The issue is that this set is not closed under linear combinations.      Yes, because it is a plane in .    Only planes through the origin are subspaces. This one is shifted and does not contain .      Compare with a homogeneous equation like . Kernels of linear maps are always subspaces.     Dimension Reasoning with a Kernel   Let be a linear transformation. Suppose the matrix of (in standard coordinates) has rank . Which of the following statements must be true?       is a ‑dimensional subspace of .    Correct. By the Rank–Nullity theorem, The section emphasizes that kernels are always subspaces and have a well‑defined dimension.       contains exactly one nonzero vector.    No. A ‑dimensional subspace contains infinitely many nonzero vectors.      Every vector in has a unique expression as with and .    No. This incorrectly suggests the range is trivial. Only the decomposition with a complementary subspace (not necessarily ) is guaranteed.       must equal .    Incorrect. is a ‑dimensional subspace of , not literally . Subspaces “look like” only in abstract structure, not as literal coordinate spaces.      Use and recall that kernels are always subspaces.     Dimension of a Kernel   Suppose a linear transformation has rank . By the Rank–Nullity Theorem, the dimension of is .    Because , we have . The section emphasizes that kernels of linear maps are subspaces with well‑defined dimension.    Use:      Subspace Check   Fill in the blank by choosing the correct statement. A set is a subspace of if it is closed under vector addition and scalar multiplication, and it must contain _____ .      the zero vector    Correct! A subspace must include , because closure under scalar multiplication requires that be in the set. This is emphasized in the subspaces section.      all standard basis vectors    No. A subspace may or may not contain individual basis vectors like or ; only closure properties matter.      every vector of    Incorrect. That would describe the entire space, not a general subspace.      all solutions to at least one linear equation    Not quite. Only homogeneous linear equations guarantee subspaces.      What vector must appear when you multiply any vector in the set by zero?      Let . Compute two sample vectors in , add them, and check whether the sum lies in . Then multiply one vector by a scalar and check whether the result lies in .    Pick two simple vectors in , for instance and . Their sum is , which is still of the form , so it lies in . Next take a scalar multiple, for example , which is again of the form , so it also lies in . These computations illustrate the closure properties that the section lists as defining a subspace.      Let as above. Express as a scalar multiple of a single vector and use this to find a basis for . Then compute the dimension of .    We can rewrite any vector in as . Hence . Because is nonzero, it is linearly independent, so is a basis for . A basis with one vector means , matching the section’s explanation that a ‑dimensional subspace behaves like .      Consider the linear transformation defined by Compute the kernel of by solving the homogeneous system and . Then find a basis for and compute its dimension.    Solving the system:  From we get . From we get . Letting , a free variable, we obtain   Thus . The basis is , and the dimension is , consistent with the theoretical description that kernels are subspaces of and have well-defined dimension.       Consider an arbitrary subset . Students often think that a subspace must “look geometric” (a line through the origin, a plane through the origin, etc.). Provide a conceptual explanation—without checking closure conditions on any specific examples—of why requiring closure under all linear combinations (not just addition or scalar multiplication alone) is the essential feature that distinguishes subspaces from general subsets.    A subspace must behave like a smaller copy of living inside , meaning that vectors can be combined in exactly the same ways we can combine ordinary vectors in —by forming any linear combination.  If a subset is closed under both addition and scalar multiplication, then it is automatically closed under all linear combinations (because is simply repeated use of these two operations). The section emphasizes that this “linear–combination stability” is what makes the solution set of a homogeneous linear system behave like a Euclidean space and justifies calling it a subspace. Without this full closure property, the set would not support the algebraic structure required for bases, dimension, or unique coordinate representations.       The notes state that while the dimension of a subspace is unique, the basis is not. Explain conceptually—without doing any computations— why a subspace can have many different bases, but cannot have more than one dimension. Use ideas from the section to justify why different bases still span “the same amount of space.”    Every basis of a subspace has two defining features: the vectors must be linearly independent, and they must span all of  . Many different choices of spanning vectors can achieve this job, because starting from one basis we can replace vectors with new ones obtained from linear combinations, as long as we maintain independence and still span the whole set. Therefore, many bases exist.  However, the number of vectors in any basis is fixed: it is the dimension of the subspace. If one basis had more vectors than another, that would contradict the meaning of “linearly independent spanning set,” since the section explains that a subspace has a unique positive integer such that every vector in can be written uniquely as a combination of independent basis vectors. This uniqueness of representation forces the dimension to be unique, even though the choice of basis is not.       The kernel of a linear transformation is defined as the set .  Provide a conceptual explanation of why the kernel must always be a subspace, and describe what this tells us about the “shape” of solution sets to homogeneous linear equations.    Because is linear, and for all scalars .  If and are in the kernel, then and , so and . Thus the kernel contains every linear combination of its vectors; it is automatically a subspace.  Conceptually, this means the solution set to any homogeneous linear system “inherits” the geometry of a Euclidean subspace: it behaves like a flat space of some dimension , possibly much smaller than . The notes highlight this by explaining that kernels look and act like once a basis has been chosen, and vectors in the kernel have unique coordinate representations in terms of that basis.       Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Determine whether a given subset of is a subspace by verifying closure under linear combinations.    Construct a basis for a subspace by extracting a linearly independent spanning set from a larger (possibly redundant) list of vectors.     Explain why every nontrivial subspace has a unique dimension and how different bases represent vectors using different coordinate tuples.      "
},
{
  "id": "mcsubspaceplane",
  "level": "2",
  "url": "ch-Textbook-21.html#mcsubspaceplane",
  "type": "Exercise",
  "number": "1",
  "title": "Is this a subspace?",
  "body": " Is this a subspace?   Consider the subset . Is a subspace of ?      Yes.    Correct. is the solution set to the homogeneous linear equation , so it is closed under all linear combinations and therefore is a subspace. (Homogeneous solution sets are kernels of linear maps.)      No, because it is “just” a plane.    Not quite. Planes through the origin defined by a homogeneous linear equation are subspaces; the key property is closure under linear combinations.      No, because it is not all of .    Subspaces need not be the whole space—they just need to contain and be closed under addition and scalar multiplication.      Sets defined as solutions to homogeneous linear equations are kernels of linear maps—kernels are subspaces.   "
},
{
  "id": "mcsubspacenonhomogeneous",
  "level": "2",
  "url": "ch-Textbook-21.html#mcsubspacenonhomogeneous",
  "type": "Exercise",
  "number": "2",
  "title": "Is this set a subspace?",
  "body": " Is this set a subspace?   Consider the subset Does form a subspace of ?      Yes, because the defining equation is linear.    Not quite. Only homogeneous linear equations (right-hand side equal to zero) define subspaces. This plane does not pass through the origin.      No, because the set does not contain the zero vector.    Correct. A subspace must contain and must be closed under all linear combinations. A nonhomogeneous equation such as cannot define a subspace. (The section explains that subspaces arise as solution sets to homogeneous equations—kernels.)      No, because it contains infinitely many points.    Subspaces can be infinite. The issue is that this set is not closed under linear combinations.      Yes, because it is a plane in .    Only planes through the origin are subspaces. This one is shifted and does not contain .      Compare with a homogeneous equation like . Kernels of linear maps are always subspaces.   "
},
{
  "id": "mcsubspacedimensionkernelchallenge",
  "level": "2",
  "url": "ch-Textbook-21.html#mcsubspacedimensionkernelchallenge",
  "type": "Exercise",
  "number": "3",
  "title": "Dimension Reasoning with a Kernel.",
  "body": " Dimension Reasoning with a Kernel   Let be a linear transformation. Suppose the matrix of (in standard coordinates) has rank . Which of the following statements must be true?       is a ‑dimensional subspace of .    Correct. By the Rank–Nullity theorem, The section emphasizes that kernels are always subspaces and have a well‑defined dimension.       contains exactly one nonzero vector.    No. A ‑dimensional subspace contains infinitely many nonzero vectors.      Every vector in has a unique expression as with and .    No. This incorrectly suggests the range is trivial. Only the decomposition with a complementary subspace (not necessarily ) is guaranteed.       must equal .    Incorrect. is a ‑dimensional subspace of , not literally . Subspaces “look like” only in abstract structure, not as literal coordinate spaces.      Use and recall that kernels are always subspaces.   "
},
{
  "id": "fibkerneldimensioneasy",
  "level": "2",
  "url": "ch-Textbook-21.html#fibkerneldimensioneasy",
  "type": "Exercise",
  "number": "4",
  "title": "Dimension of a Kernel.",
  "body": " Dimension of a Kernel   Suppose a linear transformation has rank . By the Rank–Nullity Theorem, the dimension of is .    Because , we have . The section emphasizes that kernels of linear maps are subspaces with well‑defined dimension.    Use:    "
},
{
  "id": "mcfillblanksubspace",
  "level": "2",
  "url": "ch-Textbook-21.html#mcfillblanksubspace",
  "type": "Exercise",
  "number": "5",
  "title": "Subspace Check.",
  "body": " Subspace Check   Fill in the blank by choosing the correct statement. A set is a subspace of if it is closed under vector addition and scalar multiplication, and it must contain _____ .      the zero vector    Correct! A subspace must include , because closure under scalar multiplication requires that be in the set. This is emphasized in the subspaces section.      all standard basis vectors    No. A subspace may or may not contain individual basis vectors like or ; only closure properties matter.      every vector of    Incorrect. That would describe the entire space, not a general subspace.      all solutions to at least one linear equation    Not quite. Only homogeneous linear equations guarantee subspaces.      What vector must appear when you multiply any vector in the set by zero?   "
},
{
  "id": "sec-Toprepareforclass44-4-7",
  "level": "2",
  "url": "ch-Textbook-21.html#sec-Toprepareforclass44-4-7",
  "type": "Exercise",
  "number": "6",
  "title": "",
  "body": "  Let . Compute two sample vectors in , add them, and check whether the sum lies in . Then multiply one vector by a scalar and check whether the result lies in .    Pick two simple vectors in , for instance and . Their sum is , which is still of the form , so it lies in . Next take a scalar multiple, for example , which is again of the form , so it also lies in . These computations illustrate the closure properties that the section lists as defining a subspace.   "
},
{
  "id": "sec-Toprepareforclass44-4-8",
  "level": "2",
  "url": "ch-Textbook-21.html#sec-Toprepareforclass44-4-8",
  "type": "Exercise",
  "number": "7",
  "title": "",
  "body": "  Let as above. Express as a scalar multiple of a single vector and use this to find a basis for . Then compute the dimension of .    We can rewrite any vector in as . Hence . Because is nonzero, it is linearly independent, so is a basis for . A basis with one vector means , matching the section’s explanation that a ‑dimensional subspace behaves like .   "
},
{
  "id": "sec-Toprepareforclass44-4-9",
  "level": "2",
  "url": "ch-Textbook-21.html#sec-Toprepareforclass44-4-9",
  "type": "Exercise",
  "number": "8",
  "title": "",
  "body": "  Consider the linear transformation defined by Compute the kernel of by solving the homogeneous system and . Then find a basis for and compute its dimension.    Solving the system:  From we get . From we get . Letting , a free variable, we obtain   Thus . The basis is , and the dimension is , consistent with the theoretical description that kernels are subspaces of and have well-defined dimension.   "
},
{
  "id": "sec-Toprepareforclass44-4-10",
  "level": "2",
  "url": "ch-Textbook-21.html#sec-Toprepareforclass44-4-10",
  "type": "Exercise",
  "number": "9",
  "title": "",
  "body": "  Consider an arbitrary subset . Students often think that a subspace must “look geometric” (a line through the origin, a plane through the origin, etc.). Provide a conceptual explanation—without checking closure conditions on any specific examples—of why requiring closure under all linear combinations (not just addition or scalar multiplication alone) is the essential feature that distinguishes subspaces from general subsets.    A subspace must behave like a smaller copy of living inside , meaning that vectors can be combined in exactly the same ways we can combine ordinary vectors in —by forming any linear combination.  If a subset is closed under both addition and scalar multiplication, then it is automatically closed under all linear combinations (because is simply repeated use of these two operations). The section emphasizes that this “linear–combination stability” is what makes the solution set of a homogeneous linear system behave like a Euclidean space and justifies calling it a subspace. Without this full closure property, the set would not support the algebraic structure required for bases, dimension, or unique coordinate representations.   "
},
{
  "id": "sec-Toprepareforclass44-4-11",
  "level": "2",
  "url": "ch-Textbook-21.html#sec-Toprepareforclass44-4-11",
  "type": "Exercise",
  "number": "10",
  "title": "",
  "body": "  The notes state that while the dimension of a subspace is unique, the basis is not. Explain conceptually—without doing any computations— why a subspace can have many different bases, but cannot have more than one dimension. Use ideas from the section to justify why different bases still span “the same amount of space.”    Every basis of a subspace has two defining features: the vectors must be linearly independent, and they must span all of  . Many different choices of spanning vectors can achieve this job, because starting from one basis we can replace vectors with new ones obtained from linear combinations, as long as we maintain independence and still span the whole set. Therefore, many bases exist.  However, the number of vectors in any basis is fixed: it is the dimension of the subspace. If one basis had more vectors than another, that would contradict the meaning of “linearly independent spanning set,” since the section explains that a subspace has a unique positive integer such that every vector in can be written uniquely as a combination of independent basis vectors. This uniqueness of representation forces the dimension to be unique, even though the choice of basis is not.   "
},
{
  "id": "sec-Toprepareforclass44-4-12",
  "level": "2",
  "url": "ch-Textbook-21.html#sec-Toprepareforclass44-4-12",
  "type": "Exercise",
  "number": "11",
  "title": "",
  "body": "  The kernel of a linear transformation is defined as the set .  Provide a conceptual explanation of why the kernel must always be a subspace, and describe what this tells us about the “shape” of solution sets to homogeneous linear equations.    Because is linear, and for all scalars .  If and are in the kernel, then and , so and . Thus the kernel contains every linear combination of its vectors; it is automatically a subspace.  Conceptually, this means the solution set to any homogeneous linear system “inherits” the geometry of a Euclidean subspace: it behaves like a flat space of some dimension , possibly much smaller than . The notes highlight this by explaining that kernels look and act like once a basis has been chosen, and vectors in the kernel have unique coordinate representations in terms of that basis.   "
},
{
  "id": "ch-Textbook-22",
  "level": "1",
  "url": "ch-Textbook-22.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 5.1 - Introduction to Systems of ODEs",
  "body": " Daily Prep 5.1 - Introduction to Systems of ODEs   Overview  We now introduce the idea of a system of ordinary differential equations, which arises whenever there are multiple dependent variables whose rates of change may influence one another. Instead of a single function , we may have several functions governed by multiple differential equations, each involving the variables and their derivatives. The section explains that systems can be of various orders—first‑order systems being the most common—and solutions consist of a collection of functions that simultaneously satisfy all equations in the system. Initial conditions must specify all dependent variables (and possibly their derivatives) at a given point. The section includes simple examples showing how some systems can be solved by decoupling: solving one equation first and then substituting into the others. This introduces the basic terminology and structure that lead naturally to matrix methods and linear systems in later sections.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Recognize what it means to have multiple dependent variables in a system of ODEs and understand the notation used to describe such systems.    Distinguish between first‑order and higher‑order systems and describe what constitutes a solution to a system.    Explain the form and purpose of initial conditions for systems, including specifying values of all dependent variables (and possibly derivatives) at a given point.      Learn!  Complete the actions listed below.     Read  Subsection 7.1.1: Systems .    (Optional) Watch  Introduction to Linear Systems of Differential Equations (10:15) by Katherine Heller.     Read  Subsection 7.1.2: Applications .    (Optional) Watch  Systems of Differential Equations Part 1: Modeling and Elimination (7:49) by Professor Dave Explains.     Read  Subsection 7.1.3: Changing to first order .    (Optional) Watch  Converting ODEs into Systems (6:14) by Mike, the Mathematician.     Read  Subsection 7.1.4: Autonomous systems and vector fields .     Do  Subsection 7.1.6: Exercises 7.1.2, 7.1.4, 7.1.101, 7.1.103 .      Do MyOpenMath questions from this section.     Exercises   What is a system of ODEs?   Which of the following best describes a system of ODEs?      A collection of differential equations involving several dependent variables and their derivatives.    Correct. A system consists of multiple ODEs involving several dependent variables.      A single equation that has more than one independent variable.    Incorrect. Systems involve *several dependent variables*, not multiple independent variables.      Any ODE with order greater than one.    No. Higher-order ODEs are not necessarily systems.       What is a solution to a system?   For a first-order system , what does it mean to be a solution ?      A triple of functions that satisfies all three equations simultaneously.    Correct. A solution consists of functions that satisfy every equation in the system.      Any function that satisfies at least one equation.    No. A solution must satisfy *all* equations in the system.      Only must satisfy its equation; the other functions may be arbitrary.    Incorrect. Every dependent variable must satisfy its own ODE.       Initial Conditions for Systems   For a system with dependent variables , what do appropriate initial conditions look like?      Values for each dependent variable at a point, such as , , .    Correct. An initial condition must specify each variable’s value at the starting time.      Only one initial value is needed, since the equations are linked.    No. Each variable requires its own initial value.      Only derivatives need initial values.    Incorrect for first-order systems; values of the variables themselves must be specified.       Determining the Order of a System   Consider the system What is the order of this system?      Second-order, because the highest derivatives in the system are second derivatives.    Correct. The section explains that the order of a system is the highest derivative appearing in any of the equations.     First-order, because there are two equations.   No. The number of equations does not determine order.     Fourth-order, because two second derivatives add up to order four.   Incorrect. Orders are not added; the system’s order is simply the highest derivative that appears.       Understanding a General Solution   A system of two first-order ODEs has a general solution What does this general solution represent?      A family of solutions containing two arbitrary constants, one for each initial condition of the system.    Correct. For a system with two dependent variables, the general solution contains two constants so that any initial conditions and can be matched.     A single solution valid only for the initial condition .   No. This general solution works for any initial conditions.     A solution that is valid only when .   No. and are independent constants.        Consider the pair of equations Explain why this pair of equations forms a first-order system of ODEs, and identify the dependent and independent variables.    This is a first-order system because each equation involves only the first derivatives and and no higher derivatives. A system of ODEs consists of several differential equations involving multiple dependent variables.  The dependent variables are and , and the independent variable is the implied variable (typically or ) with respect to which the derivatives are taken.      Suppose we have a first-order system What does it mean for a pair of functions to be a solution to this system?    A solution to the system is a pair of functions and that satisfy both differential equations for all relevant values of . That is, and simultaneously.  Because the system has two dependent variables, both must satisfy their equations for the pair to count as a valid solution.      Consider the system from the section: with initial conditions and . Solve for and then use it to find .    We begin by observing that the first equation, , is independent of . This makes the system decoupled in the sense described in the section: we can solve for first and then substitute it into the equation for .  Solve : the general solution is . Apply the initial condition : , hence .  Therefore,   Next, substitute into the second equation . We obtain the first-order linear ODE:   Rewrite this in standard linear form: The integrating factor is Multiplying through by the integrating factor gives Integrating both sides yields   Solving for , we get Now apply the initial condition . When we have Hence .  Therefore,   Putting both components together, the solution to the system is        Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Solve simple systems by decoupling , first solving one equation and then substituting its solution into the remaining equations.    Interpret how general solutions of systems depend on several arbitrary constants and compare this structure to the general solution of a single ODE.     Describe how a single higher‑order ODE can be rewritten as a first‑order system , motivating the matrix‑based viewpoint that follows in later sections.      "
},
{
  "id": "mcqsysdefinition",
  "level": "2",
  "url": "ch-Textbook-22.html#mcqsysdefinition",
  "type": "Exercise",
  "number": "1",
  "title": "What is a system of ODEs?",
  "body": " What is a system of ODEs?   Which of the following best describes a system of ODEs?      A collection of differential equations involving several dependent variables and their derivatives.    Correct. A system consists of multiple ODEs involving several dependent variables.      A single equation that has more than one independent variable.    Incorrect. Systems involve *several dependent variables*, not multiple independent variables.      Any ODE with order greater than one.    No. Higher-order ODEs are not necessarily systems.     "
},
{
  "id": "mcqsyssolution",
  "level": "2",
  "url": "ch-Textbook-22.html#mcqsyssolution",
  "type": "Exercise",
  "number": "2",
  "title": "What is a solution to a system?",
  "body": " What is a solution to a system?   For a first-order system , what does it mean to be a solution ?      A triple of functions that satisfies all three equations simultaneously.    Correct. A solution consists of functions that satisfy every equation in the system.      Any function that satisfies at least one equation.    No. A solution must satisfy *all* equations in the system.      Only must satisfy its equation; the other functions may be arbitrary.    Incorrect. Every dependent variable must satisfy its own ODE.     "
},
{
  "id": "mcqsysic",
  "level": "2",
  "url": "ch-Textbook-22.html#mcqsysic",
  "type": "Exercise",
  "number": "3",
  "title": "Initial Conditions for Systems.",
  "body": " Initial Conditions for Systems   For a system with dependent variables , what do appropriate initial conditions look like?      Values for each dependent variable at a point, such as , , .    Correct. An initial condition must specify each variable’s value at the starting time.      Only one initial value is needed, since the equations are linked.    No. Each variable requires its own initial value.      Only derivatives need initial values.    Incorrect for first-order systems; values of the variables themselves must be specified.     "
},
{
  "id": "mcqsysorder",
  "level": "2",
  "url": "ch-Textbook-22.html#mcqsysorder",
  "type": "Exercise",
  "number": "4",
  "title": "Determining the Order of a System.",
  "body": " Determining the Order of a System   Consider the system What is the order of this system?      Second-order, because the highest derivatives in the system are second derivatives.    Correct. The section explains that the order of a system is the highest derivative appearing in any of the equations.     First-order, because there are two equations.   No. The number of equations does not determine order.     Fourth-order, because two second derivatives add up to order four.   Incorrect. Orders are not added; the system’s order is simply the highest derivative that appears.     "
},
{
  "id": "mcqsysgeneralsolution",
  "level": "2",
  "url": "ch-Textbook-22.html#mcqsysgeneralsolution",
  "type": "Exercise",
  "number": "5",
  "title": "Understanding a General Solution.",
  "body": " Understanding a General Solution   A system of two first-order ODEs has a general solution What does this general solution represent?      A family of solutions containing two arbitrary constants, one for each initial condition of the system.    Correct. For a system with two dependent variables, the general solution contains two constants so that any initial conditions and can be matched.     A single solution valid only for the initial condition .   No. This general solution works for any initial conditions.     A solution that is valid only when .   No. and are independent constants.     "
},
{
  "id": "sysbasicidentification",
  "level": "2",
  "url": "ch-Textbook-22.html#sysbasicidentification",
  "type": "Exercise",
  "number": "6",
  "title": "",
  "body": "  Consider the pair of equations Explain why this pair of equations forms a first-order system of ODEs, and identify the dependent and independent variables.    This is a first-order system because each equation involves only the first derivatives and and no higher derivatives. A system of ODEs consists of several differential equations involving multiple dependent variables.  The dependent variables are and , and the independent variable is the implied variable (typically or ) with respect to which the derivatives are taken.   "
},
{
  "id": "syssolutionmeaning",
  "level": "2",
  "url": "ch-Textbook-22.html#syssolutionmeaning",
  "type": "Exercise",
  "number": "7",
  "title": "",
  "body": "  Suppose we have a first-order system What does it mean for a pair of functions to be a solution to this system?    A solution to the system is a pair of functions and that satisfy both differential equations for all relevant values of . That is, and simultaneously.  Because the system has two dependent variables, both must satisfy their equations for the pair to count as a valid solution.   "
},
{
  "id": "syssimpledecoupling",
  "level": "2",
  "url": "ch-Textbook-22.html#syssimpledecoupling",
  "type": "Exercise",
  "number": "8",
  "title": "",
  "body": "  Consider the system from the section: with initial conditions and . Solve for and then use it to find .    We begin by observing that the first equation, , is independent of . This makes the system decoupled in the sense described in the section: we can solve for first and then substitute it into the equation for .  Solve : the general solution is . Apply the initial condition : , hence .  Therefore,   Next, substitute into the second equation . We obtain the first-order linear ODE:   Rewrite this in standard linear form: The integrating factor is Multiplying through by the integrating factor gives Integrating both sides yields   Solving for , we get Now apply the initial condition . When we have Hence .  Therefore,   Putting both components together, the solution to the system is    "
},
{
  "id": "ch-Textbook-23",
  "level": "1",
  "url": "ch-Textbook-23.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 5.2 - Matrices and Linear Systems",
  "body": " Daily Prep 5.2 - Matrices and Linear Systems   Overview  We now introduce matrices as essential tools for studying linear systems of ODEs. The section reviews the basic structure of a matrix as an array, defines vectors as column matrices, and recalls fundamental matrix operations such as scalar multiplication, addition, and transpose. With this foundation, the section develops matrix multiplication using the dot product and emphasizes the importance of compatible dimensions (e.g., multiplying an matrix by an matrix to obtain an matrix). These operations enable us to rewrite a system of linear ODEs concisely as a single vector equation , preparing the way for later methods such as the eigenvalue approach and matrix exponentials. The goal is to transform systems into a compact algebraic form that reveals structure and makes computations more systematic.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Recall the definitions of a matrix, a column vector, and matrix size .    Perform scalar multiplication, matrix addition, and compute the transpose of a matrix.    Understand the definition of matrix multiplication using dot products and identify when the product is defined.      Learn!  Complete the actions listed below.     Read  Subsection 7.2.1: Matrices and vectors .     Read  Subsection 7.2.2: Matrix multiplication .    (Optional) Watch  Matrix Multiplication (9:35) by Mathispower4u.     Read  Subsection 7.2.3: The determinant .    (Optional) Read  Section A.6: Determinant for more details on the determinant.     Watch  Evaluating Determinants of a 2x2 and 3x2 Matrix (7:35) by Mathispower4u.     Read  Subsection 7.2.4: Solving linear systems .    (Optional) Watch  Solving a System of Linear Equations Using Inverses (6:27) by Patrick J.     Read  Subsection 7.2.5: Computing the inverse .     Do  Subsection 7.2.6: Exercises 7.2.3, 7.2.5, 7.2.6, 7.2.8, 7.2.9, 7.2.101, 7.2.103 .      Do MyOpenMath questions from this section.     Exercises   Matrix Size and Vectors   Which of the following correctly describes a column vector?      A column vector is an matrix.    Correct. A vector is treated as a column matrix in this section.     An matrix.   No—that is a row vector.     A square matrix with .   No—square matrices are unrelated to the definition of vectors.       Matrix Multiplication Rules   When is the matrix product defined?      When is and is .    Correct. The number of columns of must equal the number of rows of .     When both matrices have the same number of rows.   No. Matching rows is not the requirement.     Only when both matrices are square.   No. Matrix multiplication does not require square matrices.       Writing a System in Matrix Form   Suppose we have the system Which vector‑matrix form is correct?           Correct. The matrix is constructed from the coefficients of the system exactly as described in the section.           No. The matrix should contain constants, not variables.           This is simply rewriting the system, not expressing it as .       Understanding the Transpose   If is a matrix, what is the transpose ?      The matrix obtained by swapping rows and columns of .    Correct. The transpose flips rows into columns and vice versa.     The matrix formed by multiplying every entry of by .  No. That describes scalar multiplication by , not transposition.    The matrix you obtain by reversing the order of columns only.  No. Transpose reverses rows and columns.      Determinant and Invertibility   For a square matrix , which statement about its determinant is correct?       is invertible exactly when .    Correct. A nonzero determinant means the matrix is invertible, which is essential when rewriting or solving linear systems using .      must always be positive for to be invertible.    No. A determinant may be negative or positive; only zero prevents invertibility.      is invertible when .    Incorrect. A zero determinant means is singular and cannot be inverted.       Understanding Inverses   Suppose is a square matrix and exists. What property does satisfy?       and .    Correct. The inverse undoes the effect of , producing the identity matrix .      is obtained by transposing .    No. The transpose is generally unrelated to the inverse.      exists for every square matrix.    Incorrect. Only matrices with nonzero determinant are invertible.          Let Compute .    First compute by multiplying every entry of by 2:   Now add element‑wise:   Matrix addition and scalar multiplication work entry by entry.        Let Compute the transpose .    The transpose swaps rows and columns. So the first row of becomes the first column of , and the second row becomes the second column.         Let Compute .    Multiply each row of by the column vector using dot products, as defined in the section.  First row: .  Second row: .   This matches the definition of matrix multiplication using row–column dot products.       Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Rewrite a system of first-order linear ODEs in vector–matrix form and interpret the meaning of each component.    Verify algebraic properties of matrices (such as distributivity and compatibility with scalar multiplication) that support solving systems of ODEs.     Analyze how matrix structure (such as size and arrangement of entries) influences the behavior and solvability of linear systems.      "
},
{
  "id": "mcqmatrixsize",
  "level": "2",
  "url": "ch-Textbook-23.html#mcqmatrixsize",
  "type": "Exercise",
  "number": "1",
  "title": "Matrix Size and Vectors.",
  "body": " Matrix Size and Vectors   Which of the following correctly describes a column vector?      A column vector is an matrix.    Correct. A vector is treated as a column matrix in this section.     An matrix.   No—that is a row vector.     A square matrix with .   No—square matrices are unrelated to the definition of vectors.     "
},
{
  "id": "mcq-matrix-multiplication",
  "level": "2",
  "url": "ch-Textbook-23.html#mcq-matrix-multiplication",
  "type": "Exercise",
  "number": "2",
  "title": "Matrix Multiplication Rules.",
  "body": " Matrix Multiplication Rules   When is the matrix product defined?      When is and is .    Correct. The number of columns of must equal the number of rows of .     When both matrices have the same number of rows.   No. Matching rows is not the requirement.     Only when both matrices are square.   No. Matrix multiplication does not require square matrices.     "
},
{
  "id": "mcq-vector-form-system",
  "level": "2",
  "url": "ch-Textbook-23.html#mcq-vector-form-system",
  "type": "Exercise",
  "number": "3",
  "title": "Writing a System in Matrix Form.",
  "body": " Writing a System in Matrix Form   Suppose we have the system Which vector‑matrix form is correct?           Correct. The matrix is constructed from the coefficients of the system exactly as described in the section.           No. The matrix should contain constants, not variables.           This is simply rewriting the system, not expressing it as .     "
},
{
  "id": "mcqtranspose",
  "level": "2",
  "url": "ch-Textbook-23.html#mcqtranspose",
  "type": "Exercise",
  "number": "4",
  "title": "Understanding the Transpose.",
  "body": " Understanding the Transpose   If is a matrix, what is the transpose ?      The matrix obtained by swapping rows and columns of .    Correct. The transpose flips rows into columns and vice versa.     The matrix formed by multiplying every entry of by .  No. That describes scalar multiplication by , not transposition.    The matrix you obtain by reversing the order of columns only.  No. Transpose reverses rows and columns.    "
},
{
  "id": "mcqdeterminantinvertibility",
  "level": "2",
  "url": "ch-Textbook-23.html#mcqdeterminantinvertibility",
  "type": "Exercise",
  "number": "5",
  "title": "Determinant and Invertibility.",
  "body": " Determinant and Invertibility   For a square matrix , which statement about its determinant is correct?       is invertible exactly when .    Correct. A nonzero determinant means the matrix is invertible, which is essential when rewriting or solving linear systems using .      must always be positive for to be invertible.    No. A determinant may be negative or positive; only zero prevents invertibility.      is invertible when .    Incorrect. A zero determinant means is singular and cannot be inverted.     "
},
{
  "id": "mcqmatrixinverse",
  "level": "2",
  "url": "ch-Textbook-23.html#mcqmatrixinverse",
  "type": "Exercise",
  "number": "6",
  "title": "Understanding Inverses.",
  "body": " Understanding Inverses   Suppose is a square matrix and exists. What property does satisfy?       and .    Correct. The inverse undoes the effect of , producing the identity matrix .      is obtained by transposing .    No. The transpose is generally unrelated to the inverse.      exists for every square matrix.    Incorrect. Only matrices with nonzero determinant are invertible.     "
},
{
  "id": "matrixcomputation1",
  "level": "2",
  "url": "ch-Textbook-23.html#matrixcomputation1",
  "type": "Exercise",
  "number": "7",
  "title": "",
  "body": "   Let Compute .    First compute by multiplying every entry of by 2:   Now add element‑wise:   Matrix addition and scalar multiplication work entry by entry.   "
},
{
  "id": "matrixcomputation2",
  "level": "2",
  "url": "ch-Textbook-23.html#matrixcomputation2",
  "type": "Exercise",
  "number": "8",
  "title": "",
  "body": "   Let Compute the transpose .    The transpose swaps rows and columns. So the first row of becomes the first column of , and the second row becomes the second column.    "
},
{
  "id": "matrixcomputation3",
  "level": "2",
  "url": "ch-Textbook-23.html#matrixcomputation3",
  "type": "Exercise",
  "number": "9",
  "title": "",
  "body": "   Let Compute .    Multiply each row of by the column vector using dot products, as defined in the section.  First row: .  Second row: .   This matches the definition of matrix multiplication using row–column dot products.   "
},
{
  "id": "ch-Textbook-24",
  "level": "1",
  "url": "ch-Textbook-24.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 5.3 - Linear Systems of ODEs",
  "body": " Daily Prep 5.3 - Linear Systems of ODEs   Overview  We now introduce linear systems of ODEs by viewing them through the lens of vector‑valued and matrix‑valued functions. A first‑order linear system can be written compactly in the vector form , where is a matrix-valued function and is a vector-valued function whose components are the dependent variables. This section emphasizes the rules for differentiating matrix products and sums, which mirror ordinary differentiation but preserve matrix multiplication order. It then focuses on homogeneous systems , especially in the constant‑coefficient case, where the superposition principle holds: any linear combination of solutions is again a solution. Linear independence of vector‑valued solutions plays a central role, and if an system admits linearly independent solutions, then every solution can be written as their linear combination. Examples illustrate how to classify solutions and identify dependence relations among vector‑valued functions.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Recognize a first‑order linear system written in the vector form and identify its components.    Apply differentiation rules for matrix‑valued and vector‑valued functions, such as .    Distinguish between homogeneous systems and nonhomogeneous systems .      Learn!  Complete the actions listed below.     Read  Section 7.3: Linear systems of ODEs .    (Optional) Watch  Intro to Vector-Valued and Matrix-Valued Functions and Write a System of ODEs using Matrices (5:24) by Mathispower4u.    (Optional) Watch  Write a System of Two Differential Equations Using Matrix Notation (1:52) by Mathispower4u.    (Optional) Watch  Write a System of Three Differential Equations with Initial Values Using Matrices (3:18) by Mathispower4u.    (Optional) Watch  Intro to Solving First Order Linear Homogeneous Systems of Ordinary Differential Equations (7:48) by Mathispower4u.    (Optional) Watch  Determine if Vector-Valued Functions are Linearly Independent or Linearly Dependent (2:57) by Mathispower4u.     Do  Subsection 7.3.1: Exercises 7.3.1, 7.3.2, 7.3.3, 7.3.4, 7.3.103 .      Do MyOpenMath questions from this section.     Exercises   Identifying a Linear System   Which of the following is a valid linear first-order system of ODEs?           Correct. A linear system is defined exactly in this form.           No. Squaring the vector makes the system nonlinear.           These are first‑order ODEs but not linear .       Homogeneous vs. Nonhomogeneous   Which of the following systems is homogeneous ?           Correct. A homogeneous linear system has the form with no forcing term.           No. The presence of makes the system nonhomogeneous.           Not homogeneous; it contains nonzero added functions of .       Superposition Principle   Suppose and are solutions of the homogeneous system . Which statement is true?      Any linear combination is also a solution.    Correct. This is the superposition principle for homogeneous linear systems.      Only is a solution; scalar multiples are not.    No. All scalar multiples and linear combinations remain solutions.       is a solution only if .    No. The constants may be any real numbers.       Evaluating a Vector-Valued Function   Let Compute .           Correct. Differentiate each component: and . Then evaluate at to get and .           No. This evaluates , not its derivative.           No. The first component derivative was computed incorrectly.       Checking a Linear Combination of Solutions   Suppose are solutions to a homogeneous linear system . Compute            Correct. Multiply each vector by its scalar and add component‑wise: and . This also demonstrates the superposition principle.           No. This ignores the coefficients 3 and 2 in the linear combination.           Incorrect. The second component should include .          Consider the system Suppose two candidate solutions are Verify explicitly whether each vector‑valued function satisfies the differential equation.    For , compute the derivative:   Now compute   Since , the first function is indeed a solution of the system. This matches how we define a solution: a vector‑valued function that satisfies the matrix equation .   For , compute the derivative:   Now compute   Again we have , so the second function also satisfies the system.  Both and are valid solutions of this homogeneous linear system.        We define linear independence for vector‑valued functions using the condition for all . Consider the functions Determine whether these functions are linearly independent.    We test for constants and such that   The vector equation must hold for all . Equating components:   The second equation already forces . The first equation gives the same condition (because it must hold for all ).  Thus the solutions satisfy , giving a one‑parameter family of nontrivial combinations that equal the zero vector. Therefore, and are linearly dependent .  This matches the section’s definition: a set is dependent if a nontrivial linear combination yields for all .       Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Rewrite a system of first-order linear ODEs in vector–matrix form and interpret the meaning of each component.    Determine whether vector‑valued functions are linearly independent by checking whether a relation holds only when all constants vanish.     Express any solution of an homogeneous linear system as a linear combination of independent solutions, when such a fundamental set exists.      "
},
{
  "id": "mcqlinearsystemform",
  "level": "2",
  "url": "ch-Textbook-24.html#mcqlinearsystemform",
  "type": "Exercise",
  "number": "1",
  "title": "Identifying a Linear System.",
  "body": " Identifying a Linear System   Which of the following is a valid linear first-order system of ODEs?           Correct. A linear system is defined exactly in this form.           No. Squaring the vector makes the system nonlinear.           These are first‑order ODEs but not linear .     "
},
{
  "id": "mcqhomogeneoussystem",
  "level": "2",
  "url": "ch-Textbook-24.html#mcqhomogeneoussystem",
  "type": "Exercise",
  "number": "2",
  "title": "Homogeneous vs. Nonhomogeneous.",
  "body": " Homogeneous vs. Nonhomogeneous   Which of the following systems is homogeneous ?           Correct. A homogeneous linear system has the form with no forcing term.           No. The presence of makes the system nonhomogeneous.           Not homogeneous; it contains nonzero added functions of .     "
},
{
  "id": "mcqsuperposition",
  "level": "2",
  "url": "ch-Textbook-24.html#mcqsuperposition",
  "type": "Exercise",
  "number": "3",
  "title": "Superposition Principle.",
  "body": " Superposition Principle   Suppose and are solutions of the homogeneous system . Which statement is true?      Any linear combination is also a solution.    Correct. This is the superposition principle for homogeneous linear systems.      Only is a solution; scalar multiples are not.    No. All scalar multiples and linear combinations remain solutions.       is a solution only if .    No. The constants may be any real numbers.     "
},
{
  "id": "mcqevalvectorsolution",
  "level": "2",
  "url": "ch-Textbook-24.html#mcqevalvectorsolution",
  "type": "Exercise",
  "number": "4",
  "title": "Evaluating a Vector-Valued Function.",
  "body": " Evaluating a Vector-Valued Function   Let Compute .           Correct. Differentiate each component: and . Then evaluate at to get and .           No. This evaluates , not its derivative.           No. The first component derivative was computed incorrectly.     "
},
{
  "id": "mcqchecksuperpositioncomputation",
  "level": "2",
  "url": "ch-Textbook-24.html#mcqchecksuperpositioncomputation",
  "type": "Exercise",
  "number": "5",
  "title": "Checking a Linear Combination of Solutions.",
  "body": " Checking a Linear Combination of Solutions   Suppose are solutions to a homogeneous linear system . Compute            Correct. Multiply each vector by its scalar and add component‑wise: and . This also demonstrates the superposition principle.           No. This ignores the coefficients 3 and 2 in the linear combination.           Incorrect. The second component should include .     "
},
{
  "id": "linsysopen1",
  "level": "2",
  "url": "ch-Textbook-24.html#linsysopen1",
  "type": "Exercise",
  "number": "6",
  "title": "",
  "body": "   Consider the system Suppose two candidate solutions are Verify explicitly whether each vector‑valued function satisfies the differential equation.    For , compute the derivative:   Now compute   Since , the first function is indeed a solution of the system. This matches how we define a solution: a vector‑valued function that satisfies the matrix equation .   For , compute the derivative:   Now compute   Again we have , so the second function also satisfies the system.  Both and are valid solutions of this homogeneous linear system.   "
},
{
  "id": "linsysopen2",
  "level": "2",
  "url": "ch-Textbook-24.html#linsysopen2",
  "type": "Exercise",
  "number": "7",
  "title": "",
  "body": "   We define linear independence for vector‑valued functions using the condition for all . Consider the functions Determine whether these functions are linearly independent.    We test for constants and such that   The vector equation must hold for all . Equating components:   The second equation already forces . The first equation gives the same condition (because it must hold for all ).  Thus the solutions satisfy , giving a one‑parameter family of nontrivial combinations that equal the zero vector. Therefore, and are linearly dependent .  This matches the section’s definition: a set is dependent if a nontrivial linear combination yields for all .   "
},
{
  "id": "ch-Textbook-25",
  "level": "1",
  "url": "ch-Textbook-25.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 5.4 - Eigenvalue Method",
  "body": " Daily Prep 5.4 - Eigenvalue Method   Overview  We now introduce the eigenvalue method as a powerful technique for solving linear homogeneous constant‑coefficient systems of ODEs of the form , where is a constant square matrix. Motivated by the scalar case, the method tries solutions of the form , where is a scalar and is a constant vector. Substituting this trial form into the system reduces the differential equation to the algebraic eigenvalue problem . Thus, eigenvalues are found by solving , and each eigenvector yields a corresponding solution . Since an matrix typically has eigenvalues (possibly repeated or complex), the section shows that a collection of linearly independent eigenvector solutions forms a fundamental solution set, and all solutions are linear combinations of these. The method connects linear algebra and differential equations, enabling systematic and elegant solution of multi‑dimensional linear systems.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Recognize that the eigenvalue method applies to linear homogeneous constant‑coefficient systems .    Understand the trial solution and how substituting it leads to the eigenvalue equation .    Define eigenvalues and eigenvectors of a matrix and compute eigenvalues using .      Learn!  Complete the actions listed below.     Read  Subsection 7.4.1: Eigenvalues and eigenvectors of a matrix .     Watch  Intro to Solving a Linear System of ODEs using the Eigenvalue Method: Eigenvalues and Eigenvectors (7:17) by Mathispower4u.     Read  Subsection 7.4.2: The eigenvalue method with distinct real eigenvalues .     Watch  Solve a Linear System of ODEs using the Eigenvalue Method: Real, Distinct Eigenvalues (7:28) by Mathispower4u.    (Optional) Watch  Find Eigenvalues, Eigenvectors, and Solve a Linear System of ODEs with Constant Coefficents: Homogeneous (6:35) by Mathispower4u.    (Optional) Watch  Solve a Linear System of ODEs using the Eigenvalue Method: Real, Distinct Eigenvalues (4:08) by Mathispower4u.     Read  Subsection 7.4.3: Complex eigenvalues .     Watch  Solve a Linear System of ODEs using the Eigenvalue Method: Complex Eigenvalues (9:44) by Mathispower4u.    (Optional) Watch  Solve a Linear System of ODEs using the Eigenvalue Method: Imaginary Eigenvalues (6:38) by Mathispower4u.     Do  Subsection 7.4.4: Exercises 7.4.1, 7.4.5, 7.4.6, 7.4.7, 7.4.9, 7.4.101, 7.4.104 .      Do MyOpenMath questions from this section.     Exercises   Trial Solutions for the Eigenvalue Method   For a linear homogeneous constant‑coefficient system , what trial solution does the eigenvalue method use?         Correct. The method assumes a solution of the form .      No—the method uses exponential solutions, not linear ones.     Not in the first step. Sinusoidal behavior only appears later when eigenvalues are complex.      Obtaining the Eigenvalue Equation   After substituting into , which equation must the constants and satisfy?       Correct. The substitution leads directly to the eigenvalue equation.      No—that equation is used to find eigenvectors once is known.     No. This only holds when is a scalar matrix.      Computing Eigenvalues   To find the eigenvalues of a matrix in the system , which equation should be solved?         Correct. Eigenvalues are roots of the characteristic equation .      No. This would test whether is singular, not find eigenvalues.     This computes the nullspace, not the eigenvalues.      Computing an Eigenvalue   Let What are the eigenvalues of ?         Correct. Diagonal matrices have eigenvalues equal to their diagonal entries, consistent with solving .      No—the determinant equation does not give these roots.    only  No. A 2×2 matrix must have two eigenvalues (including repeats).      Checking an Eigenvector   Let Compute and determine the corresponding eigenvalue.           Correct. Because , the eigenvalue is . This matches the equation used in the eigenvalue method.           No. This incorrectly multiplies the matrix and vector.           No. The second component should remain zero when multiplying by this matrix.       Checking Whether a Vector is an Eigenvector   Let Compute and determine whether is an eigenvector of .       so is not an eigenvector.    Correct. Because is not a scalar multiple of , is not an eigenvector. Eigenvectors must satisfy .       so is an eigenvector with .    No. is not equal to .       , so is an eigenvector with .    No—the computation of is incorrect.       Verifying a Solution from an Eigenpair   Suppose is an eigenvalue of a constant matrix with eigenvector Which of the following is a solution of the system ?           Correct. Every eigenpair yields a solution .           No. This uses instead of .           No. Even though the vector is a scalar multiple of , the exponential must be .        Deriving the Eigenvalue Equation   Consider a linear homogeneous constant-coefficient system . Starting from the trial solution , derive the algebraic eigenvalue equation that and must satisfy. Explain each step clearly.    The trial solution used is , where is a scalar and is a constant vector. We substitute this into .  First compute the derivative:   Substitute both expressions into the differential equation:   Since is never zero, canceling it yields the purely algebraic condition:   This is exactly the eigenvalue equation. It states that must be an eigenvector of with eigenvalue . The section emphasizes this derivation as the foundation of the eigenvalue method.      Verifying an Eigenvector Solution   Let Verify that is a solution of the system .    We must check whether . Start by computing :   Compute :   Since , the vector is not an eigenvector of , and therefore is not a solution.  This exercise illustrates a key requirement: a solution of the form exists only when holds.      Constructing a General Solution from Two Eigenpairs   Suppose a system has two distinct eigenvalues and with corresponding eigenvectors Write down the general solution to the system and briefly explain why these two solutions form a fundamental set.    Since each eigenpair gives a solution , we have two independent solutions:   The general solution is the linear combination:   Because the eigenvalues and are distinct, the corresponding eigenvectors are automatically linearly independent. Hence these two solutions form a fundamental set, and every solution to the system is their linear combination, exactly as described in the theory.       Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Solve a linear system by computing eigenvectors corresponding to each eigenvalue and forming solutions of the form .    Construct the general solution of an system by forming linear combinations of linearly independent eigenvector solutions.    Analyze repeated or complex eigenvalues and determine the structure of the solution set when the eigenvectors do not provide a full set of linearly independent solutions.     "
},
{
  "id": "mcqeigentrialsolution",
  "level": "2",
  "url": "ch-Textbook-25.html#mcqeigentrialsolution",
  "type": "Exercise",
  "number": "1",
  "title": "Trial Solutions for the Eigenvalue Method.",
  "body": " Trial Solutions for the Eigenvalue Method   For a linear homogeneous constant‑coefficient system , what trial solution does the eigenvalue method use?         Correct. The method assumes a solution of the form .      No—the method uses exponential solutions, not linear ones.     Not in the first step. Sinusoidal behavior only appears later when eigenvalues are complex.    "
},
{
  "id": "mcqeigenvalueequation",
  "level": "2",
  "url": "ch-Textbook-25.html#mcqeigenvalueequation",
  "type": "Exercise",
  "number": "2",
  "title": "Obtaining the Eigenvalue Equation.",
  "body": " Obtaining the Eigenvalue Equation   After substituting into , which equation must the constants and satisfy?       Correct. The substitution leads directly to the eigenvalue equation.      No—that equation is used to find eigenvectors once is known.     No. This only holds when is a scalar matrix.    "
},
{
  "id": "mcqcharacteristicequation",
  "level": "2",
  "url": "ch-Textbook-25.html#mcqcharacteristicequation",
  "type": "Exercise",
  "number": "3",
  "title": "Computing Eigenvalues.",
  "body": " Computing Eigenvalues   To find the eigenvalues of a matrix in the system , which equation should be solved?         Correct. Eigenvalues are roots of the characteristic equation .      No. This would test whether is singular, not find eigenvalues.     This computes the nullspace, not the eigenvalues.    "
},
{
  "id": "mcqeigenvaluecomputationsmall",
  "level": "2",
  "url": "ch-Textbook-25.html#mcqeigenvaluecomputationsmall",
  "type": "Exercise",
  "number": "4",
  "title": "Computing an Eigenvalue.",
  "body": " Computing an Eigenvalue   Let What are the eigenvalues of ?         Correct. Diagonal matrices have eigenvalues equal to their diagonal entries, consistent with solving .      No—the determinant equation does not give these roots.    only  No. A 2×2 matrix must have two eigenvalues (including repeats).    "
},
{
  "id": "mcqcheckeigenvector",
  "level": "2",
  "url": "ch-Textbook-25.html#mcqcheckeigenvector",
  "type": "Exercise",
  "number": "5",
  "title": "Checking an Eigenvector.",
  "body": " Checking an Eigenvector   Let Compute and determine the corresponding eigenvalue.           Correct. Because , the eigenvalue is . This matches the equation used in the eigenvalue method.           No. This incorrectly multiplies the matrix and vector.           No. The second component should remain zero when multiplying by this matrix.     "
},
{
  "id": "mcqeigenvectordirection",
  "level": "2",
  "url": "ch-Textbook-25.html#mcqeigenvectordirection",
  "type": "Exercise",
  "number": "6",
  "title": "Checking Whether a Vector is an Eigenvector.",
  "body": " Checking Whether a Vector is an Eigenvector   Let Compute and determine whether is an eigenvector of .       so is not an eigenvector.    Correct. Because is not a scalar multiple of , is not an eigenvector. Eigenvectors must satisfy .       so is an eigenvector with .    No. is not equal to .       , so is an eigenvector with .    No—the computation of is incorrect.     "
},
{
  "id": "mcqchecksolutionform",
  "level": "2",
  "url": "ch-Textbook-25.html#mcqchecksolutionform",
  "type": "Exercise",
  "number": "7",
  "title": "Verifying a Solution from an Eigenpair.",
  "body": " Verifying a Solution from an Eigenpair   Suppose is an eigenvalue of a constant matrix with eigenvector Which of the following is a solution of the system ?           Correct. Every eigenpair yields a solution .           No. This uses instead of .           No. Even though the vector is a scalar multiple of , the exponential must be .     "
},
{
  "id": "eigenmethod-open-1",
  "level": "2",
  "url": "ch-Textbook-25.html#eigenmethod-open-1",
  "type": "Exercise",
  "number": "8",
  "title": "Deriving the Eigenvalue Equation.",
  "body": " Deriving the Eigenvalue Equation   Consider a linear homogeneous constant-coefficient system . Starting from the trial solution , derive the algebraic eigenvalue equation that and must satisfy. Explain each step clearly.    The trial solution used is , where is a scalar and is a constant vector. We substitute this into .  First compute the derivative:   Substitute both expressions into the differential equation:   Since is never zero, canceling it yields the purely algebraic condition:   This is exactly the eigenvalue equation. It states that must be an eigenvector of with eigenvalue . The section emphasizes this derivation as the foundation of the eigenvalue method.   "
},
{
  "id": "eigenmethodopen2",
  "level": "2",
  "url": "ch-Textbook-25.html#eigenmethodopen2",
  "type": "Exercise",
  "number": "9",
  "title": "Verifying an Eigenvector Solution.",
  "body": " Verifying an Eigenvector Solution   Let Verify that is a solution of the system .    We must check whether . Start by computing :   Compute :   Since , the vector is not an eigenvector of , and therefore is not a solution.  This exercise illustrates a key requirement: a solution of the form exists only when holds.   "
},
{
  "id": "eigenmethodopen3",
  "level": "2",
  "url": "ch-Textbook-25.html#eigenmethodopen3",
  "type": "Exercise",
  "number": "10",
  "title": "Constructing a General Solution from Two Eigenpairs.",
  "body": " Constructing a General Solution from Two Eigenpairs   Suppose a system has two distinct eigenvalues and with corresponding eigenvectors Write down the general solution to the system and briefly explain why these two solutions form a fundamental set.    Since each eigenpair gives a solution , we have two independent solutions:   The general solution is the linear combination:   Because the eigenvalues and are distinct, the corresponding eigenvectors are automatically linearly independent. Hence these two solutions form a fundamental set, and every solution to the system is their linear combination, exactly as described in the theory.   "
},
{
  "id": "ch-Textbook-26",
  "level": "1",
  "url": "ch-Textbook-26.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 5.5 - Two-Dimensional Systems and their Vector Fields",
  "body": " Daily Prep 5.5 - Two-Dimensional Systems and their Vector Fields   Overview  We now use two-dimensional autonomous systems of the form and show how their qualitative behavior can be understood through vector fields in the phase plane. Each point in the plane determines a direction vector , producing a picture of how solutions move over time. Because the underlying system is linear and autonomous, equilibrium points occur where , typically the origin, and the eigenvalues and eigenvectors of determine the geometry of nearby trajectories. Solutions tangent to eigenvectors form principal solution curves, while the signs and types of eigenvalues (real, repeated, or complex) determine whether the origin behaves as a node, saddle, spiral, or center. We then illustrate how the eigenvalue method combines with vector-field intuition to classify the qualitative behavior of all solutions in the plane.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Understand how a two-dimensional system defines a vector field in the plane by assigning the vector to each point .    Identify equilibrium points as solutions of and recognize that the origin is typically the unique equilibrium in a homogeneous linear system.    Describe how eigenvalues and eigenvectors of determine basic trajectory directions and qualitative motion in the phase plane .      Learn!  Complete the actions listed below.     Read  Section 7.5: Two-dimensional systems and their vector fields .     Watch  Types of Behavior of 2D Linear Homogeneous Const Coefficient Systems of ODEs Using Eigenvalues (7:55) by Mathispower4u.    (Optional) Watch  Describe the Behavior of 2D Lin Homogeneous Const Coefficient Systems of ODEs: Eigenvalues (5:12) by Mathispower4u.     Do  Subsection 7.5.1: Exercises 7.5.1, 7.5.2, 7.5.101, 7.5.102 .      Do MyOpenMath questions from this section.     Exercises   Understanding the Vector Field   For a two-dimensional linear system , what does the vector field in the phase plane represent?      At each point , the vector field assigns the direction vector .    Correct. The flow direction at each point in the plane is given by .      It assigns the length at each point.    No. Vector fields assign direction vectors, not lengths.      It assigns the scalar to every point.    No. The determinant plays a role in stability, not in defining the field.       Identifying the Equilibrium Point   For the homogeneous linear system , what is the equilibrium point?         Correct. In a homogeneous system, the equilibrium is the solution to , which is typically only the origin.      , where is any eigenvector.    No. Eigenvectors describe trajectory directions, not equilibria.      Every point in the plane is an equilibrium.    No. That occurs only in the trivial zero matrix system.       Classifying the Equilibrium   Consider the system where How is the equilibrium at the origin classified?      An unstable node.    Correct. Both eigenvalues and are positive real numbers, so solutions grow away from the origin along eigenvector directions, forming an unstable node.     A saddle point.   No. A saddle requires one positive and one negative eigenvalue.     A center.   No. Centers require purely imaginary eigenvalues.       Choose the Correct Phase Plane   Consider the system Which of the following phase portraits corresponds to this system?      (A) Unstable node    Phase portrait (A): Trajectories flow out along eigen-directions.     Correct. Both eigenvalues are positive ( and ) so the origin is an unstable node ; trajectories move outward along the eigenvector directions (the coordinate axes).      (B) Saddle    Phase portrait (B): Saddle structure (in\/out along different axes).     Not this one. A saddle requires eigenvalues of opposite signs, which is not the case here.      (C) Center    Phase portrait (C): Closed orbits (center).     Not this one. Centers correspond to purely imaginary eigenvalues (no real part), whereas both eigenvalues here are positive and real.        Describing the Vector Field and Trajectory Behavior   Consider the two-dimensional linear system (a) Describe the vector field in the phase plane, including how the direction vectors behave at various points. (b) Classify the equilibrium at the origin and explain the qualitative behavior of trajectories as .     (a) The vector field assigns to each point the direction vector . Because each component is a negative multiple of the coordinate, arrows everywhere in the plane point toward the origin. Along the -axis, the flow is horizontal toward the origin at a rate proportional to . Along the -axis, the flow is vertical toward the origin but at a faster rate proportional to . Off the axes, arrows point diagonally inward, with the -component shrinking more quickly due to the larger magnitude eigenvalue. This interpretation follows the definition of the vector field as assigning to each point.   (b) The eigenvalues of are and , both negative. According to the classification in Section 7.5, a system with two negative real eigenvalues has a stable node at the origin. Hence all trajectories approach the origin as . Because has larger magnitude, the -component decays faster, so trajectories tilt toward the -axis as they approach the origin. This is consistent with the node behavior described in the section.      Classifying a System Using Eigenvalues and Eigenvectors   Consider the system (a) Compute the eigenvalues and classify the equilibrium at the origin. (b) Based on the eigenvalues and eigenvectors, describe qualitatively what the phase portrait looks like (e.g., rotation, spiraling, or approach\/escape behavior).     (a) The characteristic equation is Therefore the eigenvalues are , a pair of purely imaginary conjugates. Purely imaginary eigenvalues correspond to a center at the origin.   (b) With purely imaginary eigenvalues, solutions neither grow nor decay in magnitude. Instead, they rotate in closed or nearly closed orbits around the origin. The vector field shows arrows tangent to ellipses or circles, depending on the eigenvector geometry. In this case, the system behaves like a constant‑speed rotation, so the phase portrait consists of closed curves (center behavior). Such systems have trajectories that circle the equilibrium rather than approaching or diverging from it.       Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Classify the behavior of the equilibrium point (node, saddle, spiral, or center) using the signs and types of eigenvalues of .    Explain how eigenvectors generate principal solution curves and how all other trajectories are organized around these directions in two-dimensional linear systems.    Relate the qualitative structure of the vector field to the general solution for distinct eigenvalues, including how the relative growth rates affect long-term behavior.     "
},
{
  "id": "mcq2dvectorfielddefinition",
  "level": "2",
  "url": "ch-Textbook-26.html#mcq2dvectorfielddefinition",
  "type": "Exercise",
  "number": "1",
  "title": "Understanding the Vector Field.",
  "body": " Understanding the Vector Field   For a two-dimensional linear system , what does the vector field in the phase plane represent?      At each point , the vector field assigns the direction vector .    Correct. The flow direction at each point in the plane is given by .      It assigns the length at each point.    No. Vector fields assign direction vectors, not lengths.      It assigns the scalar to every point.    No. The determinant plays a role in stability, not in defining the field.     "
},
{
  "id": "mcq2dequilibrium",
  "level": "2",
  "url": "ch-Textbook-26.html#mcq2dequilibrium",
  "type": "Exercise",
  "number": "2",
  "title": "Identifying the Equilibrium Point.",
  "body": " Identifying the Equilibrium Point   For the homogeneous linear system , what is the equilibrium point?         Correct. In a homogeneous system, the equilibrium is the solution to , which is typically only the origin.      , where is any eigenvector.    No. Eigenvectors describe trajectory directions, not equilibria.      Every point in the plane is an equilibrium.    No. That occurs only in the trivial zero matrix system.     "
},
{
  "id": "mcq2dclassificationeigenvalues",
  "level": "2",
  "url": "ch-Textbook-26.html#mcq2dclassificationeigenvalues",
  "type": "Exercise",
  "number": "3",
  "title": "Classifying the Equilibrium.",
  "body": " Classifying the Equilibrium   Consider the system where How is the equilibrium at the origin classified?      An unstable node.    Correct. Both eigenvalues and are positive real numbers, so solutions grow away from the origin along eigenvector directions, forming an unstable node.     A saddle point.   No. A saddle requires one positive and one negative eigenvalue.     A center.   No. Centers require purely imaginary eigenvalues.     "
},
{
  "id": "mcq-phase-plane-images",
  "level": "2",
  "url": "ch-Textbook-26.html#mcq-phase-plane-images",
  "type": "Exercise",
  "number": "4",
  "title": "Choose the Correct Phase Plane.",
  "body": " Choose the Correct Phase Plane   Consider the system Which of the following phase portraits corresponds to this system?      (A) Unstable node    Phase portrait (A): Trajectories flow out along eigen-directions.     Correct. Both eigenvalues are positive ( and ) so the origin is an unstable node ; trajectories move outward along the eigenvector directions (the coordinate axes).      (B) Saddle    Phase portrait (B): Saddle structure (in\/out along different axes).     Not this one. A saddle requires eigenvalues of opposite signs, which is not the case here.      (C) Center    Phase portrait (C): Closed orbits (center).     Not this one. Centers correspond to purely imaginary eigenvalues (no real part), whereas both eigenvalues here are positive and real.     "
},
{
  "id": "twodim-open-1",
  "level": "2",
  "url": "ch-Textbook-26.html#twodim-open-1",
  "type": "Exercise",
  "number": "5",
  "title": "Describing the Vector Field and Trajectory Behavior.",
  "body": " Describing the Vector Field and Trajectory Behavior   Consider the two-dimensional linear system (a) Describe the vector field in the phase plane, including how the direction vectors behave at various points. (b) Classify the equilibrium at the origin and explain the qualitative behavior of trajectories as .     (a) The vector field assigns to each point the direction vector . Because each component is a negative multiple of the coordinate, arrows everywhere in the plane point toward the origin. Along the -axis, the flow is horizontal toward the origin at a rate proportional to . Along the -axis, the flow is vertical toward the origin but at a faster rate proportional to . Off the axes, arrows point diagonally inward, with the -component shrinking more quickly due to the larger magnitude eigenvalue. This interpretation follows the definition of the vector field as assigning to each point.   (b) The eigenvalues of are and , both negative. According to the classification in Section 7.5, a system with two negative real eigenvalues has a stable node at the origin. Hence all trajectories approach the origin as . Because has larger magnitude, the -component decays faster, so trajectories tilt toward the -axis as they approach the origin. This is consistent with the node behavior described in the section.   "
},
{
  "id": "twodim-open-2",
  "level": "2",
  "url": "ch-Textbook-26.html#twodim-open-2",
  "type": "Exercise",
  "number": "6",
  "title": "Classifying a System Using Eigenvalues and Eigenvectors.",
  "body": " Classifying a System Using Eigenvalues and Eigenvectors   Consider the system (a) Compute the eigenvalues and classify the equilibrium at the origin. (b) Based on the eigenvalues and eigenvectors, describe qualitatively what the phase portrait looks like (e.g., rotation, spiraling, or approach\/escape behavior).     (a) The characteristic equation is Therefore the eigenvalues are , a pair of purely imaginary conjugates. Purely imaginary eigenvalues correspond to a center at the origin.   (b) With purely imaginary eigenvalues, solutions neither grow nor decay in magnitude. Instead, they rotate in closed or nearly closed orbits around the origin. The vector field shows arrows tangent to ellipses or circles, depending on the eigenvector geometry. In this case, the system behaves like a constant‑speed rotation, so the phase portrait consists of closed curves (center behavior). Such systems have trajectories that circle the equilibrium rather than approaching or diverging from it.   "
},
{
  "id": "ch-Textbook-27",
  "level": "1",
  "url": "ch-Textbook-27.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 5.6 - Second Order Systems and Applications",
  "body": " Daily Prep 5.6 - Second Order Systems and Applications   Overview  We now introduce second-order systems of differential equations, with a central focus on physical applications such as undamped mass–spring systems. Instead of rewriting these problems as large first-order systems, the section treats them directly in their natural second-order form, where the displacement vector satisfies an equation of the type , with the mass matrix and the stiffness matrix. Using Hooke’s law and Newton’s second law, the dynamics of several coupled masses can be expressed compactly in matrix notation, revealing structural patterns that generalize to an arbitrary number of masses. Because is diagonal and invertible, the system can be rewritten as , which leads to oscillatory behavior governed by the eigenvalues and eigenvectors of . The section highlights how these ideas connect discrete mass–spring models to continuum models such as the wave equation, showing how second-order systems arise naturally in many physical contexts.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Understand how to model a multi‑mass spring system using Newton’s second law and Hooke’s law to obtain a second‑order system of the form .    Identify the roles of the mass matrix  and stiffness matrix  and explain why is invertible in typical applications.    Rewrite the system as the standard form and recognize it as a linear, constant‑coefficient second-order system.      Learn!  Complete the actions listed below.     Read  Subsection 7.6.1: Undamped mass-spring systems .     Watch  Intro to Undamped Mass-Spring Systems: Second Order Systems of Ordinary Diff Equations (8:59) by Mathispower4u.     Watch  Set-up and Solve an Undamped Mass Spring System: Second Order System of ODEs (10:32) by Mathispower4u.     Read  Subsection 7.6.2: Examples .     Watch  Intro to Undamped Mass-Spring Systems with Periodic Forcing: 2nd Order Systems of ODEs (9:44) by Mathispower4u.     Read  Subsection 7.6.3: Forced oscillations .    (Optional) Watch  Solve a Linear Second Order Nonhomogeneous System of ODEs (9:28) by Mathispower4u.     Do  Subsection 7.6.4: Exercises 7.6.3, 7.6.101, 7.6.102 .      Do MyOpenMath questions from this section.     Exercises   Setting Up a Second-Order System   In the three‑mass spring system, which equation correctly represents the mathematical model obtained from Newton’s second law and Hooke’s law?         Correct. The section derives the system , where is the mass matrix and is the stiffness matrix.      No—this would describe a first‑order system, not a second‑order one.     No—Newton’s law leads to mass times acceleration on the left.      Inverting the Mass Matrix   Why is it easy to compute for the mass matrix in these models?      Because is diagonal with nonzero entries.    Correct. Each mass is nonzero, and is diagonal, so is obtained by inverting each diagonal entry.     Because for any mass–spring system.  No. The diagonal entries are the masses, not ones.    Because is symmetric.   Symmetry alone does not make inversion easy; diagonal form does.       Meaning of   After rewriting the system as , what is the significance of the matrix ?      Its eigenvalues determine the natural frequencies of the system.    Correct. The section explains that the eigenvalues of give the oscillation frequencies (normal modes) of the mass–spring system.      It measures how quickly the masses grow without bound.    No. The system models oscillations, not exponential growth.      It determines whether is invertible.    No. is invertible because the masses are nonzero.       Computing One Entry of   Consider a two‑mass system with What is the entry of ?       Correct. , so the entry is . This matches how second‑order systems become .     No—this is the entry of , not .    No—the second row would use , not the first.      Interpreting a Computed Eigenvalue   Suppose a second‑order system for some two‑mass model yields an eigenvalue . What does this tell you about the behavior of the mode corresponding to this eigenvalue?     The mode oscillates with natural frequency .   Correct. For , a negative produces oscillations with frequency . The section explains how eigenvalues of encode natural frequencies.     The mode grows exponentially without bound.  No. Exponential growth occurs when .    The mode decays exponentially to zero.  No. Negative eigenvalues in this setup produce oscillations, not decay.       Energy Interpretation of a Second-Order System   Consider a second-order system of the form , where is the mass matrix and is the stiffness matrix of an undamped mass–spring system.  (a) Explain why this system conserves mechanical energy when there is no damping. (b) Describe the physical meaning of the matrices and in terms of kinetic and potential energy.     (a) In an undamped mass–spring system, no forces remove energy from the system. The springs store potential energy and the masses carry kinetic energy , and energy simply transfers back and forth between these two forms. The equation results from applying Newton’s second law and Hooke’s law to the system, and because no damping forces are present, the total mechanical energy   remains constant. This conservation reflects exactly the behavior of the undamped multi-mass system.   (b) The matrix represents the distribution of inertia in the system. Because it is diagonal with entries , the kinetic energy term   is exactly . The stiffness matrix encodes how the springs resist displacement. The potential energy stored in the system is   Off-diagonal entries of represent coupling between masses (neighboring displacements affect each other), while diagonal entries reflect how strongly the system resists stretching at each mass location. This matches the physical interpretation provided alongside the construction of and in the text.      Understanding Normal Modes Without Calculation   Suppose a three-mass undamped spring system is modeled by . Let the eigenvalues and eigenvectors of be , , and .  Explain, in words and without doing any computation, what the motion looks like when the system is started exactly in the shape of the eigenvector with some initial velocity along . Why does no other mode appear in the motion?    If the initial displacement and velocity are both multiples of , then the system begins in the exact shape of the second normal mode . Each eigenpair produces an independent oscillatory solution , and that the general motion is a linear combination of these normal modes.  Because form a basis of independent modes, any displacement can be written as a combination of them. But if the initial state lies entirely in the direction of , there is no component of or in the initial condition. Therefore the solution must remain a pure oscillation of the form   with frequency . No other frequency can appear because there is no component of the initial state aligned with the other eigenvectors. This is exactly the decoupling property of normal modes.       Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Analyze the oscillatory behavior of the system by studying the eigenvalues and eigenvectors of , interpreting them as natural frequencies and normal modes.    Extend the mass–spring formulation to larger numbers of masses and identify the matrix patterns that generalize to -mass systems.    Explain how discrete multi‑mass models converge conceptually to continuum models such as the one‑dimensional wave equation by letting the number of masses grow large.     "
},
{
  "id": "mcqsecondordersetup",
  "level": "2",
  "url": "ch-Textbook-27.html#mcqsecondordersetup",
  "type": "Exercise",
  "number": "1",
  "title": "Setting Up a Second-Order System.",
  "body": " Setting Up a Second-Order System   In the three‑mass spring system, which equation correctly represents the mathematical model obtained from Newton’s second law and Hooke’s law?         Correct. The section derives the system , where is the mass matrix and is the stiffness matrix.      No—this would describe a first‑order system, not a second‑order one.     No—Newton’s law leads to mass times acceleration on the left.    "
},
{
  "id": "mcqsecondorderinversion",
  "level": "2",
  "url": "ch-Textbook-27.html#mcqsecondorderinversion",
  "type": "Exercise",
  "number": "2",
  "title": "Inverting the Mass Matrix.",
  "body": " Inverting the Mass Matrix   Why is it easy to compute for the mass matrix in these models?      Because is diagonal with nonzero entries.    Correct. Each mass is nonzero, and is diagonal, so is obtained by inverting each diagonal entry.     Because for any mass–spring system.  No. The diagonal entries are the masses, not ones.    Because is symmetric.   Symmetry alone does not make inversion easy; diagonal form does.     "
},
{
  "id": "mcqsecondordereigen",
  "level": "2",
  "url": "ch-Textbook-27.html#mcqsecondordereigen",
  "type": "Exercise",
  "number": "3",
  "title": "Meaning of <span class=\"process-math\">\\(M^{-1}K\\)<\/span>.",
  "body": " Meaning of   After rewriting the system as , what is the significance of the matrix ?      Its eigenvalues determine the natural frequencies of the system.    Correct. The section explains that the eigenvalues of give the oscillation frequencies (normal modes) of the mass–spring system.      It measures how quickly the masses grow without bound.    No. The system models oscillations, not exponential growth.      It determines whether is invertible.    No. is invertible because the masses are nonzero.     "
},
{
  "id": "mcqsecondordercomputeMinvK1",
  "level": "2",
  "url": "ch-Textbook-27.html#mcqsecondordercomputeMinvK1",
  "type": "Exercise",
  "number": "4",
  "title": "Computing One Entry of <span class=\"process-math\">\\(M^{-1}K\\)<\/span>.",
  "body": " Computing One Entry of   Consider a two‑mass system with What is the entry of ?       Correct. , so the entry is . This matches how second‑order systems become .     No—this is the entry of , not .    No—the second row would use , not the first.    "
},
{
  "id": "mcqsecondordereigenvaluesign",
  "level": "2",
  "url": "ch-Textbook-27.html#mcqsecondordereigenvaluesign",
  "type": "Exercise",
  "number": "5",
  "title": "Interpreting a Computed Eigenvalue.",
  "body": " Interpreting a Computed Eigenvalue   Suppose a second‑order system for some two‑mass model yields an eigenvalue . What does this tell you about the behavior of the mode corresponding to this eigenvalue?     The mode oscillates with natural frequency .   Correct. For , a negative produces oscillations with frequency . The section explains how eigenvalues of encode natural frequencies.     The mode grows exponentially without bound.  No. Exponential growth occurs when .    The mode decays exponentially to zero.  No. Negative eigenvalues in this setup produce oscillations, not decay.    "
},
{
  "id": "secondorderopennew1",
  "level": "2",
  "url": "ch-Textbook-27.html#secondorderopennew1",
  "type": "Exercise",
  "number": "6",
  "title": "Energy Interpretation of a Second-Order System.",
  "body": " Energy Interpretation of a Second-Order System   Consider a second-order system of the form , where is the mass matrix and is the stiffness matrix of an undamped mass–spring system.  (a) Explain why this system conserves mechanical energy when there is no damping. (b) Describe the physical meaning of the matrices and in terms of kinetic and potential energy.     (a) In an undamped mass–spring system, no forces remove energy from the system. The springs store potential energy and the masses carry kinetic energy , and energy simply transfers back and forth between these two forms. The equation results from applying Newton’s second law and Hooke’s law to the system, and because no damping forces are present, the total mechanical energy   remains constant. This conservation reflects exactly the behavior of the undamped multi-mass system.   (b) The matrix represents the distribution of inertia in the system. Because it is diagonal with entries , the kinetic energy term   is exactly . The stiffness matrix encodes how the springs resist displacement. The potential energy stored in the system is   Off-diagonal entries of represent coupling between masses (neighboring displacements affect each other), while diagonal entries reflect how strongly the system resists stretching at each mass location. This matches the physical interpretation provided alongside the construction of and in the text.   "
},
{
  "id": "secondorderopennew2",
  "level": "2",
  "url": "ch-Textbook-27.html#secondorderopennew2",
  "type": "Exercise",
  "number": "7",
  "title": "Understanding Normal Modes Without Calculation.",
  "body": " Understanding Normal Modes Without Calculation   Suppose a three-mass undamped spring system is modeled by . Let the eigenvalues and eigenvectors of be , , and .  Explain, in words and without doing any computation, what the motion looks like when the system is started exactly in the shape of the eigenvector with some initial velocity along . Why does no other mode appear in the motion?    If the initial displacement and velocity are both multiples of , then the system begins in the exact shape of the second normal mode . Each eigenpair produces an independent oscillatory solution , and that the general motion is a linear combination of these normal modes.  Because form a basis of independent modes, any displacement can be written as a combination of them. But if the initial state lies entirely in the direction of , there is no component of or in the initial condition. Therefore the solution must remain a pure oscillation of the form   with frequency . No other frequency can appear because there is no component of the initial state aligned with the other eigenvectors. This is exactly the decoupling property of normal modes.   "
},
{
  "id": "ch-Textbook-28",
  "level": "1",
  "url": "ch-Textbook-28.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 5.7 - Multiple Eigenvalues",
  "body": " Daily Prep 5.7 - Multiple Eigenvalues   Overview  We now examine what happens in linear systems of ODEs when the coefficient matrix possesses multiple eigenvalues , especially repeated real eigenvalues. The section explains that having a repeated eigenvalue does not guarantee that the system has enough linearly independent eigenvectors to form a complete solution set. When only one eigenvector exists for a repeated eigenvalue, the system is called defective , and a generalized eigenvector must be found to construct a second linearly independent solution of the form . The method parallels the procedure for repeated roots of constant‑coefficient scalar equations but must be handled in vector form. The section shows how generalized eigenvectors arise from solving , and illustrates how the resulting solutions produce phase‑plane behavior distinct from the simple node cases with two eigenvectors. These ideas are essential for completing the eigenvalue method when the matrix is not diagonalizable.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Recognize when a matrix has a repeated eigenvalue and determine when it lacks a full set of independent eigenvectors.    Understand the difference between a diagonalizable matrix (with enough eigenvectors) and a defective matrix (with fewer eigenvectors than its algebraic multiplicity).    Identify the need for generalized eigenvectors when a repeated eigenvalue does not produce enough independent solutions.      Learn!  Complete the actions listed below.     Read  Subsection 7.7.1: Geometric multiplicity .     Watch  Intro to Solving a Linear System of ODEs using the Eigenvalue Method: Repeated Eigenvalues (9:47) by Mathispower4u.     Read  Subsection 7.7.2: Defective eigenvalues .    (Optional) Watch  Solve a Linear System of ODEs using the Eigenvalue Method: Repeated Eigenvalues, 1 Defect (5:27) by Mathispower4u.    (Optional) Watch  Multiple Eigenvalue Solutions, Part 1 (31:29) by Susan Brooks.    (Optional) Watch  Dealing with deficient eigenvalues (51:50) by Steve Butler (Beard Meets Calculus) of Iowa State University.     Do  Subsection 7.7.3: Exercises 7.7.2, 7.7.3, 7.7.5, 7.7.101, 7.7.102, 7.7.103 .      Do MyOpenMath questions from this section.     Exercises   Recognizing a Repeated Eigenvalue   The matrix has which eigenvalues?     A repeated eigenvalue .   Correct. The characteristic polynomial is , so the eigenvalue has multiplicity 2.     Eigenvalues and .  No—the diagonal entries do not directly give distinct eigenvalues in this case.    Eigenvalues and with multiplicity one each.  No—the eigenvalue is repeated, not distinct.      Determining When a Matrix Is Defective   A matrix with a repeated eigenvalue is called defective when:      It has fewer independent eigenvectors than the multiplicity of .    Correct. A repeated eigenvalue requires enough eigenvectors; if only one exists, the matrix is defective.     Its characteristic polynomial cannot be factored.  No. This has nothing to do with being defective.    Its trace is zero.  No. The trace does not determine diagonalizability.      Purpose of a Generalized Eigenvector   If a matrix has only one eigenvector for a repeated eigenvalue, why do we introduce a generalized eigenvector ?      To construct a second independent solution of the form .    Correct. A generalized eigenvector provides the missing second solution when only one eigenvector exists.     To find a new eigenvalue.  No—generalized eigenvectors do not create new eigenvalues.    To force the matrix to become diagonalizable.   No. A defective matrix cannot be made diagonalizable by choosing more vectors.       Equation for Finding a Generalized Eigenvector   If is an eigenvector for a repeated eigenvalue , which equation must a generalized eigenvector satisfy?       Correct. This equation produces a vector that generates the second independent solution.     No—that would make another eigenvector, which does not exist.    Not the defining equation—the generalized eigenvector is found using .      Structure of the General Solution for a Defective Matrix   If a matrix has a repeated eigenvalue with only one eigenvector and a generalized eigenvector , what does the general solution to look like?           Correct. This is the full solution when only one eigenvector exists.      No—this does not produce two independent solutions.     No—solutions must be vector‑valued and use and .       Checking Whether a Matrix Is Defective   Consider the matrix     Compute the eigenvalue(s) of .    Find all eigenvectors of and determine whether the matrix is defective.       (a) The characteristic polynomial is , so the only eigenvalue is the repeated eigenvalue .   (b) To find the eigenvectors, solve . That matrix is   The equation implies , while is free. Thus every eigenvector has the form   There is only one linearly independent eigenvector, even though the eigenvalue has algebraic multiplicity 2. Hence is defective .      Finding a Generalized Eigenvector   Let which has a repeated eigenvalue . The unique eigenvector (up to scaling) is .  Find a generalized eigenvector satisfying .    Compute   We seek such that   Thus , and is arbitrary. The simplest choice is   This exactly matches the definition of a generalized eigenvector: solve .      Constructing the Full Solution for a Defective Matrix   For the matrix the eigenvalue is with eigenvector . A generalized eigenvector is .  Write the general solution to .    A defective matrix with one eigenvector and one generalized eigenvector yields solutions   Therefore the general solution is   This is the standard repeated‑eigenvalue solution for a defective system.       Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Find a generalized eigenvector by solving when only one eigenvector exists for a repeated eigenvalue.    Construct a complete solution for a defective system of the form and explain why these solutions remain linearly independent.    Analyze how repeated eigenvalues and generalized eigenvectors affect qualitative phase‑plane behavior, distinguishing these cases from ordinary nodes with two eigenvectors.     "
},
{
  "id": "mcqmulteigenrepeated",
  "level": "2",
  "url": "ch-Textbook-28.html#mcqmulteigenrepeated",
  "type": "Exercise",
  "number": "1",
  "title": "Recognizing a Repeated Eigenvalue.",
  "body": " Recognizing a Repeated Eigenvalue   The matrix has which eigenvalues?     A repeated eigenvalue .   Correct. The characteristic polynomial is , so the eigenvalue has multiplicity 2.     Eigenvalues and .  No—the diagonal entries do not directly give distinct eigenvalues in this case.    Eigenvalues and with multiplicity one each.  No—the eigenvalue is repeated, not distinct.    "
},
{
  "id": "mcqmulteigendefective",
  "level": "2",
  "url": "ch-Textbook-28.html#mcqmulteigendefective",
  "type": "Exercise",
  "number": "2",
  "title": "Determining When a Matrix Is Defective.",
  "body": " Determining When a Matrix Is Defective   A matrix with a repeated eigenvalue is called defective when:      It has fewer independent eigenvectors than the multiplicity of .    Correct. A repeated eigenvalue requires enough eigenvectors; if only one exists, the matrix is defective.     Its characteristic polynomial cannot be factored.  No. This has nothing to do with being defective.    Its trace is zero.  No. The trace does not determine diagonalizability.    "
},
{
  "id": "mcqmulteigengeneralized",
  "level": "2",
  "url": "ch-Textbook-28.html#mcqmulteigengeneralized",
  "type": "Exercise",
  "number": "3",
  "title": "Purpose of a Generalized Eigenvector.",
  "body": " Purpose of a Generalized Eigenvector   If a matrix has only one eigenvector for a repeated eigenvalue, why do we introduce a generalized eigenvector ?      To construct a second independent solution of the form .    Correct. A generalized eigenvector provides the missing second solution when only one eigenvector exists.     To find a new eigenvalue.  No—generalized eigenvectors do not create new eigenvalues.    To force the matrix to become diagonalizable.   No. A defective matrix cannot be made diagonalizable by choosing more vectors.     "
},
{
  "id": "mcqmulteigenequation",
  "level": "2",
  "url": "ch-Textbook-28.html#mcqmulteigenequation",
  "type": "Exercise",
  "number": "4",
  "title": "Equation for Finding a Generalized Eigenvector.",
  "body": " Equation for Finding a Generalized Eigenvector   If is an eigenvector for a repeated eigenvalue , which equation must a generalized eigenvector satisfy?       Correct. This equation produces a vector that generates the second independent solution.     No—that would make another eigenvector, which does not exist.    Not the defining equation—the generalized eigenvector is found using .    "
},
{
  "id": "mcqmulteigensolutionform",
  "level": "2",
  "url": "ch-Textbook-28.html#mcqmulteigensolutionform",
  "type": "Exercise",
  "number": "5",
  "title": "Structure of the General Solution for a Defective Matrix.",
  "body": " Structure of the General Solution for a Defective Matrix   If a matrix has a repeated eigenvalue with only one eigenvector and a generalized eigenvector , what does the general solution to look like?           Correct. This is the full solution when only one eigenvector exists.      No—this does not produce two independent solutions.     No—solutions must be vector‑valued and use and .    "
},
{
  "id": "multeigennew1",
  "level": "2",
  "url": "ch-Textbook-28.html#multeigennew1",
  "type": "Exercise",
  "number": "6",
  "title": "Checking Whether a Matrix Is Defective.",
  "body": " Checking Whether a Matrix Is Defective   Consider the matrix     Compute the eigenvalue(s) of .    Find all eigenvectors of and determine whether the matrix is defective.       (a) The characteristic polynomial is , so the only eigenvalue is the repeated eigenvalue .   (b) To find the eigenvectors, solve . That matrix is   The equation implies , while is free. Thus every eigenvector has the form   There is only one linearly independent eigenvector, even though the eigenvalue has algebraic multiplicity 2. Hence is defective .   "
},
{
  "id": "multeigennew2",
  "level": "2",
  "url": "ch-Textbook-28.html#multeigennew2",
  "type": "Exercise",
  "number": "7",
  "title": "Finding a Generalized Eigenvector.",
  "body": " Finding a Generalized Eigenvector   Let which has a repeated eigenvalue . The unique eigenvector (up to scaling) is .  Find a generalized eigenvector satisfying .    Compute   We seek such that   Thus , and is arbitrary. The simplest choice is   This exactly matches the definition of a generalized eigenvector: solve .   "
},
{
  "id": "multeigennew3",
  "level": "2",
  "url": "ch-Textbook-28.html#multeigennew3",
  "type": "Exercise",
  "number": "8",
  "title": "Constructing the Full Solution for a Defective Matrix.",
  "body": " Constructing the Full Solution for a Defective Matrix   For the matrix the eigenvalue is with eigenvector . A generalized eigenvector is .  Write the general solution to .    A defective matrix with one eigenvector and one generalized eigenvector yields solutions   Therefore the general solution is   This is the standard repeated‑eigenvalue solution for a defective system.   "
},
{
  "id": "ch-Textbook-29",
  "level": "1",
  "url": "ch-Textbook-29.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 5.8 - Matrix Exponentials",
  "body": " Daily Prep 5.8 - Matrix Exponentials   Overview  It is time to introduce the matrix exponential -- a powerful method for solving linear constant‑coefficient systems of differential equations of the form . Motivated by the scalar solution , the section defines the matrix exponential via its convergent Taylor series , and demonstrates that this function satisfies the key identity . This establishes as the general solution to the system, and in particular . The section explains that matrix exponentials provide a fundamental matrix solution and give a clean way to solve initial value problems directly. It also highlights an important subtlety: in contrast to real numbers, matrices do not generally commute, so unless and satisfy . Finally, the section explores simple cases—especially diagonal and triangular matrices—where matrix exponentials can be computed efficiently.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Understand the definition of the matrix exponential  and recognize it as a convergent power series for any square matrix .    Verify that and conclude that solves the system .    Use the formula to solve initial value problems for linear homogeneous constant‑coefficient systems.      Learn!  Complete the actions listed below.     Read  Subsection 7.8.1: Definition .     Read  Subsection 7.8.2: Simple cases .     Watch  Intro to Matrix Exponentials and Determining Matrix Exponentials for Simple Cases (10:35) by Mathispower4u.    (Optional) Watch  The Matrix Exponential (15:31) by Gilbert Strang (from MIT OpenCourseWare).     Read  Subsection 7.8.3: General matrices .     Watch  Matrix Exponentials for the General Case: N by N with N Linearly Indep Eigenvectors (7:40) by Mathispower4u.     Read  Subsection 7.8.4: Fundamental matrix solutions .    (Optional) Watch  Determine a Matrix Exponential and General Solution to x'=Ax: 3 by 3 General Case (5:49) by Mathispower4u.    (Optional) Watch  How (and why) to raise e to the power of a matrix (27:06) by 3Blue1Brown.     Do  Subsection 7.8.6: Exercises 7.8.2, 7.8.3, 7.8.4, 7.8.5, 7.8.101, 7.8.103 .      Do MyOpenMath questions from this section.     Exercises   Definition of the Matrix Exponential   Which of the following correctly defines the matrix exponential for a square matrix ?           Correct. The matrix exponential is defined using the power‑series expansion.      No—this only works for special matrices, not in general.     No—raising a matrix to a real power is unrelated to the exponential.      Why Solves the System   Why does solve the system ?      Because .    Correct. Differentiating the series term‑by‑term gives , so multiplying by yields a solution.     Because diagonalizes every matrix .  No—only some matrices are diagonalizable.    Because for all .  No—this is only true when .      Solving an IVP with the Matrix Exponential   For the system with initial condition , what is the solution?       Correct. The general solution is , and implies .      No—this expression is not defined and is not the solution.     No—the exponential must apply to the matrix, not to a scalar.      Matrix Exponential of a Diagonal Matrix   If what is ?           Correct. For diagonal matrices, the exponential is taken on each diagonal entry.      No—the exponential does not distribute in that way.         No—the exponentials must be applied directly to the diagonal entries.      When Does Hold?   When is the identity true?     When and commute: .   Correct. The section warns that the identity generally fails unless and commute.     Always, for all square matrices.  No—this is false even for simple 2×2 matrices.    Only when both and are diagonal.  Not quite—diagonal matrices commute, but commutativity (not diagonality) is the real requirement.       Using the Series Definition to Compute a Simple Matrix Exponential   Let Compute directly from the power series definition of the matrix exponential:     First compute powers of . Since we find:   Thus the power series truncates after the first term involving :   Nilpotent matrices make the exponential easy to compute using the series.      Solving an Initial Value Problem Using the Matrix Exponential   Consider the system Use the matrix exponential to solve for .    Because the matrix is diagonal, the matrix exponential is computed by exponentiating each diagonal entry:   The solution to with is . Therefore:       Understanding Commutativity and Matrix Exponential Identities   Let     Show that and commute.    Use this fact to compute in terms of and .       (a) Compute and :    Thus . When matrices commute, the exponential identity holds.   (b) Since is diagonal,   Also,   Multiply them:   This confirms the commutativity‑dependent identity emphasized in the section.      Matrix Exponential of a Diagonal 3×3 Matrix   Compute the matrix exponential for the diagonal matrix     For a diagonal matrix, the matrix exponential is obtained by exponentiating each diagonal entry individually.   No off‑diagonal terms appear since powers of a diagonal matrix remain diagonal and the Taylor series keeps all entries separated.      Solving a 3×3 System Using the Matrix Exponential   Consider the system with initial condition Compute and then find .    First compute powers of . This matrix is strictly upper triangular, so it is nilpotent:   By the series definition of the matrix exponential since all higher powers vanish.   Adding these gives   Now compute :   Therefore the solution to the system is   This illustrates how matrix exponentials solve triangular (nilpotent) systems.      Matrix Exponential via Jordan Form (One Jordan Block)   Consider the matrix     Explain why has a repeated eigenvalue and why it is not diagonalizable.    Compute using the identity , where is the Jordan form of .       (a) The characteristic polynomial is   so is a repeated eigenvalue of multiplicity 3. The matrix has only one independent eigenvector because it is a single Jordan block. Therefore is not diagonalizable.   (b) Since is already in Jordan form, we have and . A size‑3 Jordan block satisfies   where is the nilpotent part:   Therefore,       Similarity Transform Required: Block with Repeated Eigenvalue   Consider the matrix     Find a matrix such that is a Jordan matrix consisting of a Jordan block and one block.    Compute using .       (a) The eigenvalues of are (multiplicity 2) and . For , we find:   Solving gives an eigenvector . To find a generalized eigenvector , solve :   giving , , and free. Choose .  For , the eigenvector is   Thus a convenient choice is   which already puts into Jordan form:    (b) The Jordan block for eigenvalue yields   For the block we get . Therefore   Since , we have , hence:        Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Compute matrix exponentials in special cases, including diagonal matrices (applying the exponential entrywise) and triangular matrices (where powers of can be computed systematically).    Explain why only when and commute, and understand how this affects solving systems by splitting the matrix into simpler parts.    Recognize the matrix exponential as a fundamental matrix solution and understand how it relates to the theory of diagonalization, generalized eigenvectors, and the eigenvalue method for solving systems.     "
},
{
  "id": "mcqmatexpdefinition",
  "level": "2",
  "url": "ch-Textbook-29.html#mcqmatexpdefinition",
  "type": "Exercise",
  "number": "1",
  "title": "Definition of the Matrix Exponential.",
  "body": " Definition of the Matrix Exponential   Which of the following correctly defines the matrix exponential for a square matrix ?           Correct. The matrix exponential is defined using the power‑series expansion.      No—this only works for special matrices, not in general.     No—raising a matrix to a real power is unrelated to the exponential.    "
},
{
  "id": "mcqmatexpsatisfiesode",
  "level": "2",
  "url": "ch-Textbook-29.html#mcqmatexpsatisfiesode",
  "type": "Exercise",
  "number": "2",
  "title": "Why <span class=\"process-math\">\\(e^{tP}\\)<\/span> Solves the System.",
  "body": " Why Solves the System   Why does solve the system ?      Because .    Correct. Differentiating the series term‑by‑term gives , so multiplying by yields a solution.     Because diagonalizes every matrix .  No—only some matrices are diagonalizable.    Because for all .  No—this is only true when .    "
},
{
  "id": "mcqmatexpivp",
  "level": "2",
  "url": "ch-Textbook-29.html#mcqmatexpivp",
  "type": "Exercise",
  "number": "3",
  "title": "Solving an IVP with the Matrix Exponential.",
  "body": " Solving an IVP with the Matrix Exponential   For the system with initial condition , what is the solution?       Correct. The general solution is , and implies .      No—this expression is not defined and is not the solution.     No—the exponential must apply to the matrix, not to a scalar.    "
},
{
  "id": "mcqmatexpdiagonal",
  "level": "2",
  "url": "ch-Textbook-29.html#mcqmatexpdiagonal",
  "type": "Exercise",
  "number": "4",
  "title": "Matrix Exponential of a Diagonal Matrix.",
  "body": " Matrix Exponential of a Diagonal Matrix   If what is ?           Correct. For diagonal matrices, the exponential is taken on each diagonal entry.      No—the exponential does not distribute in that way.         No—the exponentials must be applied directly to the diagonal entries.    "
},
{
  "id": "mcqmatexpcommutation",
  "level": "2",
  "url": "ch-Textbook-29.html#mcqmatexpcommutation",
  "type": "Exercise",
  "number": "5",
  "title": "When Does <span class=\"process-math\">\\(e^{A+B} = e^{A} e^{B}\\)<\/span> Hold?",
  "body": " When Does Hold?   When is the identity true?     When and commute: .   Correct. The section warns that the identity generally fails unless and commute.     Always, for all square matrices.  No—this is false even for simple 2×2 matrices.    Only when both and are diagonal.  Not quite—diagonal matrices commute, but commutativity (not diagonality) is the real requirement.    "
},
{
  "id": "matexpnew1",
  "level": "2",
  "url": "ch-Textbook-29.html#matexpnew1",
  "type": "Exercise",
  "number": "6",
  "title": "Using the Series Definition to Compute a Simple Matrix Exponential.",
  "body": " Using the Series Definition to Compute a Simple Matrix Exponential   Let Compute directly from the power series definition of the matrix exponential:     First compute powers of . Since we find:   Thus the power series truncates after the first term involving :   Nilpotent matrices make the exponential easy to compute using the series.   "
},
{
  "id": "matexpnew2",
  "level": "2",
  "url": "ch-Textbook-29.html#matexpnew2",
  "type": "Exercise",
  "number": "7",
  "title": "Solving an Initial Value Problem Using the Matrix Exponential.",
  "body": " Solving an Initial Value Problem Using the Matrix Exponential   Consider the system Use the matrix exponential to solve for .    Because the matrix is diagonal, the matrix exponential is computed by exponentiating each diagonal entry:   The solution to with is . Therefore:    "
},
{
  "id": "matexp-new-3",
  "level": "2",
  "url": "ch-Textbook-29.html#matexp-new-3",
  "type": "Exercise",
  "number": "8",
  "title": "Understanding Commutativity and Matrix Exponential Identities.",
  "body": " Understanding Commutativity and Matrix Exponential Identities   Let     Show that and commute.    Use this fact to compute in terms of and .       (a) Compute and :    Thus . When matrices commute, the exponential identity holds.   (b) Since is diagonal,   Also,   Multiply them:   This confirms the commutativity‑dependent identity emphasized in the section.   "
},
{
  "id": "matexp3x3problem1",
  "level": "2",
  "url": "ch-Textbook-29.html#matexp3x3problem1",
  "type": "Exercise",
  "number": "9",
  "title": "Matrix Exponential of a Diagonal 3×3 Matrix.",
  "body": " Matrix Exponential of a Diagonal 3×3 Matrix   Compute the matrix exponential for the diagonal matrix     For a diagonal matrix, the matrix exponential is obtained by exponentiating each diagonal entry individually.   No off‑diagonal terms appear since powers of a diagonal matrix remain diagonal and the Taylor series keeps all entries separated.   "
},
{
  "id": "matexp3x3problem2",
  "level": "2",
  "url": "ch-Textbook-29.html#matexp3x3problem2",
  "type": "Exercise",
  "number": "10",
  "title": "Solving a 3×3 System Using the Matrix Exponential.",
  "body": " Solving a 3×3 System Using the Matrix Exponential   Consider the system with initial condition Compute and then find .    First compute powers of . This matrix is strictly upper triangular, so it is nilpotent:   By the series definition of the matrix exponential since all higher powers vanish.   Adding these gives   Now compute :   Therefore the solution to the system is   This illustrates how matrix exponentials solve triangular (nilpotent) systems.   "
},
{
  "id": "matexp-3by3-repeated-1",
  "level": "2",
  "url": "ch-Textbook-29.html#matexp-3by3-repeated-1",
  "type": "Exercise",
  "number": "11",
  "title": "Matrix Exponential via Jordan Form (One Jordan Block).",
  "body": " Matrix Exponential via Jordan Form (One Jordan Block)   Consider the matrix     Explain why has a repeated eigenvalue and why it is not diagonalizable.    Compute using the identity , where is the Jordan form of .       (a) The characteristic polynomial is   so is a repeated eigenvalue of multiplicity 3. The matrix has only one independent eigenvector because it is a single Jordan block. Therefore is not diagonalizable.   (b) Since is already in Jordan form, we have and . A size‑3 Jordan block satisfies   where is the nilpotent part:   Therefore,    "
},
{
  "id": "matexp-3by3-repeated-2",
  "level": "2",
  "url": "ch-Textbook-29.html#matexp-3by3-repeated-2",
  "type": "Exercise",
  "number": "12",
  "title": "Similarity Transform Required: Block with Repeated Eigenvalue.",
  "body": " Similarity Transform Required: Block with Repeated Eigenvalue   Consider the matrix     Find a matrix such that is a Jordan matrix consisting of a Jordan block and one block.    Compute using .       (a) The eigenvalues of are (multiplicity 2) and . For , we find:   Solving gives an eigenvector . To find a generalized eigenvector , solve :   giving , , and free. Choose .  For , the eigenvector is   Thus a convenient choice is   which already puts into Jordan form:    (b) The Jordan block for eigenvalue yields   For the block we get . Therefore   Since , we have , hence:    "
},
{
  "id": "ch-Textbook-30",
  "level": "1",
  "url": "ch-Textbook-30.html",
  "type": "Handout",
  "number": "",
  "title": "Daily Prep 5.9 - Nonhomogeneous Systems",
  "body": " Daily Prep 5.9 - Nonhomogeneous Systems   Overview  We now develop methods for solving nonhomogeneous linear systems of the form . Building on the matrix exponential from earlier, the section introduces the variation‑of‑parameters formula, which expresses the general solution as the sum of a homogeneous solution and a particular solution obtained through an integral involving left‑multiplication by . Specifically, the solution is . The section emphasizes that the exponential acts on the nonhomogeneous forcing by “propagating” its influence forward through time, mirroring the convolution structure familiar from single‑equation ODEs. Several examples—especially involving exponential, polynomial, and sinusoidal forcing—demonstrate how this integral formula provides a systematic approach even when guessing a particular solution would be difficult or impossible.    Basic learning objectives  These are the tasks you should be able to perform with reasonable fluency when you arrive at our next class meeting. Important new vocabulary words are indicated in italics .    Recognize a nonhomogeneous linear system of the form and understand how it differs from the homogeneous case.    Understand that the homogeneous solution is and that a particular solution must be added to form the general solution.    Know the variation‑of‑parameters formula as the standard method of solving nonhomogeneous systems.      Learn!  Complete the actions listed below.     Read  Subsection 7.9.1: First order constant coefficient .     Read  Subsubsection 7.9.1.3: Undetermined coefficients .     Read  Subsection 7.9.2: First order variable coefficient .     Read  Subsection 7.9.3: Second order constant coefficients .    (Optional) Watch  Nonhomogeneous ODE systems (50:05) by Steve Butler (Beard Meets Calculus).     Do  Subsection 7.9.4: Exercises 7.9.101, 7.9.102 .      Do MyOpenMath questions from this section.     Exercises   Identifying a Nonhomogeneous System   Which of the following is a nonhomogeneous linear system?         Correct. A nonhomogeneous system includes an external forcing term .      No forcing term is present—this is the homogeneous case.      No—this system has no matrix term and is not linear in the usual sense of Section 7.9.       General Solution Formula   What is the general solution to the nonhomogeneous system ?           Correct. This is the variation‑of‑parameters formula.        No—the forcing term must be integrated, not simply added.       No—this does not solve the differential equation.      Meaning of in the Integral   In the variation‑of‑parameters integral , what does represent?      The propagation of the forcing forward to time .    Correct. The exponential transports the effect of the forcing from the earlier time to the current time .     The derivative of .  No—nothing in the integral computes a derivative of the forcing.    An antiderivative of .  No— is the matrix exponential of .      Simple Computation in the Diagonal Case   Suppose Which expression correctly represents the integrand ?           Correct. For diagonal , the exponential is diagonal, and the integrand is a product of this exponential and .        No—this ignores the dependence on and the forcing vector.       No—the integral requires , not evaluation at .      Solving an IVP Conceptually   To solve the initial value problem which of the following steps is correct?      Compute .    Correct. This is precisely the initial‑value formula.     Solve only the homogeneous system and ignore .  No—this omits the contribution of the forcing term.    Integrate alone and multiply by .  No—this does not account for the system dynamics.       Solving a Nonhomogeneous System with Diagonal A   Consider the system Use the variation-of-parameters formula to find an explicit expression for .    The solution of with is   For the diagonal matrix ,   Therefore,   The homogeneous part is:   The particular part is:   Compute the integrals:    Putting everything together:   Hence the solution is       Constant Forcing with Triangular Matrix   Solve the system Use variation of parameters; do not use undetermined coefficients.    The matrix exponential for an upper triangular matrix with repeated eigenvalue is:   Consider the formula   Compute the homogeneous part:   Next compute the integrand:   Integrate from to :    Thus the particular solution is:   Combining homogeneous and particular parts:       Interpreting the Forcing Term Through the Matrix Exponential   Consider the nonhomogeneous system where .    Describe qualitatively how the forcing term influences the motion using the matrix exponential .    Compute .       (a) The forcing enters through the integral   where “propagates” the contribution of forward from time to . Since is a rotation matrix, is a rotation by . Thus the forcing term (a vertical oscillation) gets rotated and accumulated over time. The net effect is that the system experiences a continuously rotating contribution from , producing a driven rotational motion.   (b) Because represents a 90-degree rotation, its exponential is the usual rotation matrix:   This follows from the Taylor series expansion and is used directly inside the nonhomogeneous integral.       Advanced learning objectives  In addition to mastering the basic objectives, here are the tasks you should be able to perform, with practice:    Compute particular solutions by evaluating , including cases where is exponential, polynomial, or sinusoidal.    Use properties of the matrix exponential (e.g., behavior under commuting matrices, simplifications for triangular or diagonalizable matrices) to streamline the computation of inside the variation‑of‑parameters integral.    Interpret the integral formula as a matrix‑valued convolution that “accumulates” the forcing term over time, explaining how the effect of forcing is propagated forward through the dynamics defined by .     "
},
{
  "id": "mcq-nonhomog-basic-form",
  "level": "2",
  "url": "ch-Textbook-30.html#mcq-nonhomog-basic-form",
  "type": "Exercise",
  "number": "1",
  "title": "Identifying a Nonhomogeneous System.",
  "body": " Identifying a Nonhomogeneous System   Which of the following is a nonhomogeneous linear system?         Correct. A nonhomogeneous system includes an external forcing term .      No forcing term is present—this is the homogeneous case.      No—this system has no matrix term and is not linear in the usual sense of Section 7.9.     "
},
{
  "id": "mcq-nonhomog-solution-form",
  "level": "2",
  "url": "ch-Textbook-30.html#mcq-nonhomog-solution-form",
  "type": "Exercise",
  "number": "2",
  "title": "General Solution Formula.",
  "body": " General Solution Formula   What is the general solution to the nonhomogeneous system ?           Correct. This is the variation‑of‑parameters formula.        No—the forcing term must be integrated, not simply added.       No—this does not solve the differential equation.    "
},
{
  "id": "mcq-nonhomog-epropagation",
  "level": "2",
  "url": "ch-Textbook-30.html#mcq-nonhomog-epropagation",
  "type": "Exercise",
  "number": "3",
  "title": "Meaning of <span class=\"process-math\">\\(e^{(t-s)A}\\)<\/span> in the Integral.",
  "body": " Meaning of in the Integral   In the variation‑of‑parameters integral , what does represent?      The propagation of the forcing forward to time .    Correct. The exponential transports the effect of the forcing from the earlier time to the current time .     The derivative of .  No—nothing in the integral computes a derivative of the forcing.    An antiderivative of .  No— is the matrix exponential of .    "
},
{
  "id": "mcq-nonhomog-diagonal-case",
  "level": "2",
  "url": "ch-Textbook-30.html#mcq-nonhomog-diagonal-case",
  "type": "Exercise",
  "number": "4",
  "title": "Simple Computation in the Diagonal Case.",
  "body": " Simple Computation in the Diagonal Case   Suppose Which expression correctly represents the integrand ?           Correct. For diagonal , the exponential is diagonal, and the integrand is a product of this exponential and .        No—this ignores the dependence on and the forcing vector.       No—the integral requires , not evaluation at .    "
},
{
  "id": "mcq-nonhomog-initial-value",
  "level": "2",
  "url": "ch-Textbook-30.html#mcq-nonhomog-initial-value",
  "type": "Exercise",
  "number": "5",
  "title": "Solving an IVP Conceptually.",
  "body": " Solving an IVP Conceptually   To solve the initial value problem which of the following steps is correct?      Compute .    Correct. This is precisely the initial‑value formula.     Solve only the homogeneous system and ignore .  No—this omits the contribution of the forcing term.    Integrate alone and multiply by .  No—this does not account for the system dynamics.    "
},
{
  "id": "nonhomog-open-1",
  "level": "2",
  "url": "ch-Textbook-30.html#nonhomog-open-1",
  "type": "Exercise",
  "number": "6",
  "title": "Solving a Nonhomogeneous System with Diagonal A.",
  "body": " Solving a Nonhomogeneous System with Diagonal A   Consider the system Use the variation-of-parameters formula to find an explicit expression for .    The solution of with is   For the diagonal matrix ,   Therefore,   The homogeneous part is:   The particular part is:   Compute the integrals:    Putting everything together:   Hence the solution is    "
},
{
  "id": "nonhomog-open-2",
  "level": "2",
  "url": "ch-Textbook-30.html#nonhomog-open-2",
  "type": "Exercise",
  "number": "7",
  "title": "Constant Forcing with Triangular Matrix.",
  "body": " Constant Forcing with Triangular Matrix   Solve the system Use variation of parameters; do not use undetermined coefficients.    The matrix exponential for an upper triangular matrix with repeated eigenvalue is:   Consider the formula   Compute the homogeneous part:   Next compute the integrand:   Integrate from to :    Thus the particular solution is:   Combining homogeneous and particular parts:    "
},
{
  "id": "nonhomog-open-3",
  "level": "2",
  "url": "ch-Textbook-30.html#nonhomog-open-3",
  "type": "Exercise",
  "number": "8",
  "title": "Interpreting the Forcing Term Through the Matrix Exponential.",
  "body": " Interpreting the Forcing Term Through the Matrix Exponential   Consider the nonhomogeneous system where .    Describe qualitatively how the forcing term influences the motion using the matrix exponential .    Compute .       (a) The forcing enters through the integral   where “propagates” the contribution of forward from time to . Since is a rotation matrix, is a rotation by . Thus the forcing term (a vertical oscillation) gets rotated and accumulated over time. The net effect is that the system experiences a continuously rotating contribution from , producing a driven rotational motion.   (b) Because represents a 90-degree rotation, its exponential is the usual rotation matrix:   This follows from the Taylor series expansion and is used directly inside the nonhomogeneous integral.   "
}
]

var ptx_lunr_idx = lunr(function () {
  this.ref('id')
  this.field('title')
  this.field('body')
  this.metadataWhitelist = ['position']

  ptx_lunr_docs.forEach(function (doc) {
    this.add(doc)
  }, this)
})
